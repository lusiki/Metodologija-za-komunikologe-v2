---
title: "RaÄunalna analiza teksta u istraÅ¾ivanju masovne komunikacije"
format: 
  html:
    toc: true
    toc-depth: 3
    number-sections: true
    theme: cosmo
    code-fold: true
lang: hr
---

# Uvod u raÄunalnu analizu teksta

Zamislimo istraÅ¾ivaÄa koji prouÄava medijsku konstrukciju, odnosno naÄin na koji mediji izvjeÅ¡tavaju o klimatskim promjenama u hrvatskom javnom prostoru. Pred sobom ima korpus od stotinu tisuÄ‡a Älanaka objavljenih na vodeÄ‡im informativnim portalima tijekom posljednjeg desetljeÄ‡a, tisuÄ‡e kolumni, eseja, Älanaka u kojem se prenose reakcije politiÄara i predlaÅ¾u odreÄ‘ene javne politike, politiÄkih govora, stotine tisuÄ‡a komentara Äitatelja i objava na druÅ¡tvenim mreÅ¾ama. Tradicionalnim metodama klasiÄne analize sadrÅ¾aja, Äak i s timom od desetak kodiraÄa koji rade puno radno vrijeme, analiza ovako opseÅ¾nog materijala trajala bi godinama. No pitanja koja istraÅ¾ivaÄ Å¾eli postaviti zahtijevaju upravo takav opseg jer se tiÄu suptilnih promjena u diskursu kroz vrijeme, razlika izmeÄ‘u medija razliÄitih politiÄkih orijentacija, dinamike javne rasprave i naÄina na koji se znanstveni konsenzus prevodi u medijske narative. Upravo u takvim situacijama raÄunalna analiza teksta postaje nezamjenjiv metodoloÅ¡ki alat.

RaÄunalna analiza teksta, poznata i pod nazivima *text mining*, *computational text analysis* ili *text as data*, predstavlja skup metoda koje koriste raÄunalne algoritme za sustavno ekstrahiranje informacija iz nestrukturiranih tekstualnih podataka (Grimmer, Roberts i Stewart, 2022). U kontekstu istraÅ¾ivanja masovne komunikacije, ove metode omoguÄ‡uju analizu korpusa veliÄine i sloÅ¾enosti koja bi bila nedostiÅ¾na tradicionalnim pristupima, otvarajuÄ‡i nova istraÅ¾ivaÄka pitanja i pruÅ¾ajuÄ‡i empirijsku osnovu za teorije koje su ranije bile testirane samo na ograniÄenim uzorcima.

VaÅ¾nost raÄunalne analize teksta za komunikoloÅ¡ka istraÅ¾ivanja proizlazi iz nekoliko konvergentnih trendova. S jedne strane, digitalizacija medijskog prostora generira enormne koliÄine tekstualnih podataka koji dokumentiraju javnu komunikaciju u neviÄ‘enoj granularnosti. Svaki Älanak na informativnom portalu, svaka objava na druÅ¡tvenim mreÅ¾ama, svaki komentar Äitatelja predstavlja potencijalni izvor uvida u medijsku dinamiku javne sfere. S druge strane, napredak u raÄunalnoj lingvistici i strojnom uÄenju pruÅ¾a sve sofisticiranije alate za obradu i analizu tih podataka. Konvergencija obilnih podataka i moÄ‡nih alata otvara nove horizonte za empirijsko istraÅ¾ivanje komunikacijskih fenomena.

## EpistemoloÅ¡ke pretpostavke raÄunalne analize teksta

Ulazak u svijet raÄunalne analize teksta zahtijeva od istraÅ¾ivaÄa ne samo tehniÄke vjeÅ¡tine, veÄ‡ i temeljito razumijevanje epistemoloÅ¡kih pretpostavki, moguÄ‡nosti i ograniÄenja ovih metoda. ÄŒetiri su vaÅ¾ne pretpostavke koje vrijede za sve metode raÄunalne analize teksta i koje svaki istraÅ¾ivaÄ mora usvojiti prije nego Å¡to pristupi primjeni ovih tehnika (Grimmer, Roberts i Stewart, 2022).

**Prva pretpostavka** glasi da sve kvantitativne modele tekstualnih podataka treba tretirati kao pogreÅ¡ne, ali potencijalno korisne.

**Druga pretpostavka** istiÄe da kvantitativne metode za tekst pojaÄavaju ljudske sposobnosti, ali ih ne zamjenjuju. RaÄunalna analiza moÅ¾e obraditi koliÄine teksta koje bi bile nemoguÄ‡e za ljudsku analizu, identificirati obrasce koji bi promakli ljudskom oku i kvantificirati fenomene na naÄin koji omoguÄ‡uje statistiÄko zakljuÄivanje. MeÄ‘utim, raÄunala ne "razumiju" tekst u smislu u kojem to Äine ljudi. Interpretacija rezultata, procjena njihove smislenosti, povezivanje s teorijskim okvirima i donoÅ¡enje zakljuÄaka ostaju ljudske zadaÄ‡e. PokuÅ¡aj potpune automatizacije istraÅ¾ivaÄkog procesa gotovo sigurno vodi do trivijalnih ili pogreÅ¡nih zakljuÄaka.

**TreÄ‡a pretpostavka** naglaÅ¡ava da je potrebna ekstenzivna validacija specifiÄna za problem. Ne postoji univerzalni algoritam koji funkcionira za sve istraÅ¾ivaÄke zadatke i sve korpuse. Metoda koja izvrsno funkcionira za klasifikaciju vijesti prema temama moÅ¾da Ä‡e podbaciti za analizu sentimenta u komentarima na druÅ¡tvenim mreÅ¾ama. Algoritam treniran na engleskim tekstovima neÄ‡e nuÅ¾no dobro funkcionirati na hrvatskim tekstovima. Zato je svako istraÅ¾ivanje duÅ¾no ukljuÄiti rigoroznu validaciju koja demonstrira da odabrane metode proizvode valjane rezultate u specifiÄnom kontekstu primjene.

**ÄŒetvrta pretpostavka** upozorava da raÄunalne metode za tekst ne otklanjaju potrebu za pomnim Äitanjem i analitiÄkim razmiÅ¡ljanjem. Upravo suprotno, one zahtijevaju joÅ¡ viÅ¡e pomnog Äitanja jer istraÅ¾ivaÄ mora razumjeti podatke koje analizira, mora moÄ‡i procijeniti smislenost rezultata algoritama i mora znati interpretirati kvantitativne nalaze u svjetlu kvalitativnog razumijevanja tekstualnog materijala. RaÄunalna analiza ne eliminira interpretaciju, veÄ‡ joj pruÅ¾a kvantitativnu podlogu.

Razumijevanje ovih pretpostavki posebno je vaÅ¾no u kontekstu komunikoloÅ¡kih istraÅ¾ivanja gdje su pitanja znaÄenja, interpretacije i konteksta centralna. Za razliku od analize numeriÄkih podataka gdje postoji relativno jasna veza izmeÄ‘u mjerenja i koncepta, tekstualni podaci zahtijevaju interpretativni korak koji model ne moÅ¾e obaviti autonomno. Algoritam moÅ¾e prebrojati rijeÄi, izraÄunati statistiÄke obrasce i grupirati dokumente prema sliÄnosti, ali ne moÅ¾e razumjeti ironiju, prepoznati kulturne reference ili procijeniti relevantnost nalaza za teorijska pitanja discipline.

Ukratko, raÄunalna analiza teksta nije Äarobno rjeÅ¡enje koje automatizira istraÅ¾ivaÄki proces, veÄ‡ sofisticirani alat koji, kada se koristi promiÅ¡ljeno, moÅ¾e znaÄajno proÅ¡iriti doseg i dubinu komunikoloÅ¡kih istraÅ¾ivanja. UspjeÅ¡na primjena zahtijeva ne samo tehniÄke vjeÅ¡tine, veÄ‡ i teorijsku sofisticiranost, kritiÄku refleksiju i kontinuirani dijalog izmeÄ‘u kvantitativnih metoda i kvalitativnog razumijevanja.

## Pregled faza raÄunalne analize teksta

Proces raÄunalne analize teksta moÅ¾e se konceptualizirati kao niz uzastopnih faza od kojih svaka gradi na rezultatima prethodne. Cijeli se postupak sastoji od sljedeÄ‡ih faza:

1. **Priprema podataka za analizu** obuhvaÄ‡a tokenizaciju, uklanjanje zaustavnih rijeÄi, stemizaciju ili lematizaciju te ÄiÅ¡Ä‡enje i normalizaciju teksta. U ovoj se fazi sirovi tekst transformira u strukturirani oblik pogodan za kvantitativnu obradu.

2. **Reprezentacija teksta** odnosi se na pretvaranje pripremljenog teksta u matematiÄke strukture (vektore ili matrice) koje omoguÄ‡uju statistiÄku analizu. Temeljni modeli reprezentacije ukljuÄuju model vreÄ‡e rijeÄi, TF-IDF vaganje i matrice supojavljivanja.

3. **Analiza teksta** primjenjuje statistiÄke i raÄunalne metode na pripremljene podatke radi odgovora na istraÅ¾ivaÄka pitanja. Osnovne vrste analize ukljuÄuju nadzirano strojno uÄenje, tematsko modeliranje, analizu sentimenta i ekstrakciju entiteta.

4. **Analiza na razini diskursa** ispituje Å¡ire jeziÄne obrasce poput kolokacija, okvira, retoriÄke strukture i mreÅ¾nih odnosa meÄ‘u rijeÄima, nadograÄ‘ujuÄ‡i se na temeljne analitiÄke postupke.

5. **Validacija i interpretacija rezultata** predstavlja zavrÅ¡nu, ali nimalo manje vaÅ¾nu fazu u kojoj se provjerava valjanost i pouzdanost rezultata te donose zakljuÄci u svjetlu teorijskog okvira istraÅ¾ivanja.

U programskom okruÅ¾enju, sve se navedene faze provode uz pomoÄ‡ specijaliziranih softverskih paketa. U ovom se poglavlju kao referentni alat koristi programski jezik R, koji nudi bogat ekosustav paketa za analizu teksta. NajvaÅ¾niji meÄ‘u njima su **quanteda** (Benoit i sur., 2018) za konstrukciju korpusa, tokenizaciju i izradu matrica dokument-termin, **tidytext** (Silge i Robinson, 2017) za integraciju analize teksta s tidyverse pristupom te **topicmodels** za tematsko modeliranje. Alternativno, Python s bibliotekama poput NLTK, spaCy i scikit-learn nudi usporedive moguÄ‡nosti.

U nastavku poglavlja svaka od navedenih faza detaljno se objaÅ¡njava, s posebnim osvrtom na primjere iz hrvatskog medijskog prostora i na specifiÄne izazove koji proizlaze iz karakteristika hrvatskog jezika. Uz konceptualno objaÅ¡njenje svake faze, navode se i praktiÄne upute za njezinu provedbu.


# Priprema podataka za analizu

Priprema podataka prvi je i temeljni korak u raÄunalnoj analizi teksta. Cilj ove faze jest transformirati sirovi, nestrukturirani tekst u oblik pogodan za kvantitativnu obradu. Zamislimo situaciju u kojoj istraÅ¾ivaÄ masovne komunikacije Å¾eli analizirati viÅ¡e od pedeset tisuÄ‡a komentara Äitatelja objavljenih ispod Älanaka vodeÄ‡ih hrvatskih informativnih portala tijekom jedne izborne kampanje. Sirovi tekst koji prikuplja iz digitalnog okruÅ¾enja predstavlja kaotiÄan niz znakova, interpunkcijskih oznaka, pogreÅ¡no napisanih rijeÄi, emotikona i raznovrsnih tipografskih varijacija. Komentar poput "neznam sta bi reko o ovim politicarimaâ€¦ DOSTA JE!!! ğŸ˜¡ğŸ˜¡ğŸ˜¡ #izbori2024" sadrÅ¾i pravopisne pogreÅ¡ke, ispuÅ¡tene dijakritiÄke znakove, viÅ¡estruke interpunkcijske znakove, emotikone i hashtag. Takav materijal u svom izvornom obliku nije pogodan za sustavnu analizu jer analitiÄke metode zahtijevaju odreÄ‘enu razinu strukturiranosti i konzistentnosti podataka. Priprema podataka stoga predstavlja temeljni korak koji prethodi svakoj raÄunalno potpomognutoj analizi teksta, a njezina kvaliteta izravno odreÄ‘uje valjanost i pouzdanost konaÄnih rezultata istraÅ¾ivanja.

Proces pripreme podataka obuhvaÄ‡a niz postupaka kojima se nestrukturirani tekst transformira u oblik prikladan za kvantitativnu obradu. MoÅ¾e se reÄ‡i da ovaj postupak predstavlja svojevrsni most izmeÄ‘u sirovog jeziÄnog materijala i njegova numeriÄkog prikaza koji omoguÄ‡uje primjenu statistiÄkih i raÄunalnih metoda. Valja napomenuti da odluke donesene u ovoj fazi imaju dalekoseÅ¾ne posljedice jer svako pojednostavljenje teksta nuÅ¾no ukljuÄuje odreÄ‘eni gubitak informacija. IstraÅ¾ivaÄ stoga mora paÅ¾ljivo balansirati izmeÄ‘u potrebe za redukcijom sloÅ¾enosti i oÄuvanja semantiÄki relevantnih svojstava teksta.

Priprema podataka nije neutralan tehniÄki postupak veÄ‡ epistemoloÅ¡ki Äin koji odraÅ¾ava teorijske pretpostavke istraÅ¾ivaÄa o prirodi jezika i komunikacije. Kada se odluÄuje koje elemente teksta zadrÅ¾ati, a koje odbaciti, implicitno se definira Å¡to se smatra znaÄajnim za istraÅ¾ivaÄko pitanje. Upravo zato je od iznimne vaÅ¾nosti da istraÅ¾ivaÄ razumije logiku svakoga koraka u procesu pripreme te da svoje odluke moÅ¾e argumentirano obrazloÅ¾iti.

Priprema podataka obuhvaÄ‡a Äetiri kljuÄna koraka koji se detaljno razmatraju u nastavku: tokenizaciju, uklanjanje zaustavnih rijeÄi, stemizaciju ili lematizaciju te ÄiÅ¡Ä‡enje i normalizaciju teksta. Svaki od ovih koraka ukljuÄuje specifiÄne analitiÄke odluke, a za njihovu provedbu koriste se specijalizirani softverski alati.

## Tokenizacija kao temeljna operacija

Prva i najtemeljnija operacija u pripremi tekstualnih podataka jest tokenizacija, postupak raÅ¡Älanjivanja kontinuiranog niza teksta na diskretne jedinice koje se nazivaju tokenima. Token predstavlja najmanju jedinicu analize, a ovisno o istraÅ¾ivaÄkom pitanju moÅ¾e predstavljati pojedinaÄnu rijeÄ, n-gram, reÄenicu ili odlomak. U kontekstu istraÅ¾ivanja masovne komunikacije najÄeÅ¡Ä‡e se kao token koristi pojedinaÄna rijeÄ buduÄ‡i da rijeÄi predstavljaju temeljne nositelje znaÄenja u jeziku.

Premda se tokenizacija moÅ¾e Äiniti trivijalnom operacijom koja se svodi na razdvajanje teksta prema razmacima, u praksi ovaj postupak ukljuÄuje niz odluka koje mogu znaÄajno utjecati na rezultate analize. Promotrimo reÄenicu "Predsjednik Vlade RH g. Novak posjetio je tvrtku XY." Jednostavna tokenizacija prema razmacima proizvela bi tokene: ["Predsjednik", "Vlade", "RH", "g.", "Novak", "posjetio", "je", "tvrtku", "XY."]. MeÄ‘utim, ovakva tokenizacija postavlja nekoliko pitanja. Treba li "RH" tretirati kao token ili proÅ¡iriti u "Republika Hrvatska"? Kako postupiti s kraticom "g." koja ukljuÄuje toÄku? Je li "XY." jedan token ili treba odvojiti interpunkciju? Odgovori na ova pitanja ovise o specifiÄnostima istraÅ¾ivaÄkog pitanja i karakteristikama korpusa.

@tbl-tokenizacija prikazuje razliÄite strategije tokenizacije i njihove rezultate za odabrani primjer reÄenice.

| Strategija tokenizacije | Rezultat za "XY." | Rezultat za "g." | Broj tokena |
|:------------------------|:------------------|:-----------------|:------------|
| Jednostavna (razmaci) | XY. | g. | 9 |
| S odvajanjem interpunkcije | XY, . | g, . | 11 |
| S rastavljanjem crtica | XY, . | g, . | 11 |
| Normalizirana | xy | g | 8 |

: Usporedba strategija tokenizacije na primjeru reÄenice "Predsjednik Vlade RH g. Novak posjetio je tvrtku XY." {#tbl-tokenizacija}

Za hrvatske tekstove dodatnu komplikaciju predstavljaju enklitike, kratke nenaglaÅ¡ene rijeÄi koje se u govoru veÅ¾u uz prethodnu ili sljedeÄ‡u rijeÄ. U pisanom tekstu one su odvojene razmacima, no njihova gramatiÄka funkcija vezana je uz druge rijeÄi u reÄenici. Primjerice, u reÄenici "Vidjeli smo ga" zamjenica "ga" funkcionira kao objekt glagola, no tokenizacija je tretira kao zasebnu jedinicu, Å¡to je ispravno za veÄ‡inu analiza.

U praksi se tokenizacija provodi pomoÄ‡u specijaliziranih softverskih alata koji automatiziraju proces i rjeÅ¡avaju veÄ‡inu navedenih problema. Paket quanteda u programskom jeziku R nudi funkciju `tokens()` koja omoguÄ‡uje fleksibilnu kontrolu nad procesom tokenizacije, ukljuÄujuÄ‡i opcije za uklanjanje interpunkcije, brojeva i URL adresa. Alternativno, Python biblioteka spaCy nudi naprednu tokenizaciju s podrÅ¡kom za hrvatski jezik putem viÅ¡ejeziÄnih modela.


## Uklanjanje zaustavnih rijeÄi

Nakon tokenizacije, korpus tipiÄno sadrÅ¾i velik broj visokofrekventnih rijeÄi koje nose malo semantiÄke vrijednosti. RijeÄi poput "i", "ili", "je", "su", "na", "u", "za" pojavljuju se u gotovo svakom dokumentu i dominiraju distribucijom frekvencija. Ove se rijeÄi konvencionalno nazivaju zaustavnim rijeÄima (eng. *stop words*) jer ne doprinose razlikovanju dokumenata prema sadrÅ¾aju. U analizi tematske strukture korpusa novinarskih Älanaka, Äinjenica da svi Älanci sadrÅ¾e veznik "i" ne govori niÅ¡ta o njihovu sadrÅ¾aju. Uklanjanje zaustavnih rijeÄi stoga smanjuje dimenzionalnost podataka i poboljÅ¡ava omjer signala i Å¡uma u analizi.

TipiÄna lista zaustavnih rijeÄi za hrvatski jezik sadrÅ¾i nekoliko stotina najÄeÅ¡Ä‡ih rijeÄi ukljuÄujuÄ‡i veznike, prijedloge, pomoÄ‡ne glagole i najÄeÅ¡Ä‡e zamjenice. MeÄ‘utim, sastavljanje takve liste nije trivijalan zadatak i ukljuÄuje interpretativne odluke. Je li rijeÄ "moÅ¾e" zaustavna rijeÄ ili sadrÅ¾ajna rijeÄ? Odgovor ovisi o kontekstu istraÅ¾ivanja. U korpusu politiÄkih govora, modalni glagoli poput "moÅ¾e", "mora", "treba" mogu nositi znaÄajnu informaciju o diskurzivnim strategijama govornika. U tehniÄkim tekstovima, iste rijeÄi moÅ¾da nemaju takvu funkciju.

@tbl-stopwords prikazuje primjer tipiÄnih hrvatskih zaustavnih rijeÄi organiziranih prema vrstama rijeÄi.

| Vrsta rijeÄi | Primjeri zaustavnih rijeÄi |
|:-------------|:---------------------------|
| Veznici | i, ili, ali, nego, jer, da, kako, dok, kad |
| Prijedlozi | u, na, za, s, sa, od, do, iz, po, o, prema |
| Zamjenice | ja, ti, on, ona, ono, mi, vi, oni, one, ona, ovaj, taj, onaj |
| PomoÄ‡ni glagoli | sam, si, je, smo, ste, su, biti, jesam, nisam |
| ÄŒestice | li, ne, ni, joÅ¡, veÄ‡, samo, baÅ¡, Äak |

: Primjeri hrvatskih zaustavnih rijeÄi prema vrstama rijeÄi {#tbl-stopwords}

Uklanjanje zaustavnih rijeÄi moÅ¾e se provesti koriÅ¡tenjem unaprijed definiranih lista ili automatski, identificiranjem rijeÄi Äija frekvencija prelazi odreÄ‘eni prag. Oba pristupa imaju prednosti i nedostatke. Unaprijed definirane liste omoguÄ‡uju preciznu kontrolu, ali zahtijevaju prilagodbu specifiÄnom korpusu. Automatski pristupi su fleksibilniji, ali mogu ukloniti rijeÄi koje su relevantne za specifiÄno istraÅ¾ivaÄko pitanje. PreporuÄljivo je da istraÅ¾ivaÄ pregleda listu zaustavnih rijeÄi i prilagodi je potrebama svog istraÅ¾ivanja.

Za praktiÄnu provedbu uklanjanja zaustavnih rijeÄi, paket quanteda nudi ugraÄ‘ene liste zaustavnih rijeÄi za mnoge jezike, ukljuÄujuÄ‡i hrvatski. IstraÅ¾ivaÄ moÅ¾e koristiti postojeÄ‡u listu, proÅ¡iriti je vlastitim rijeÄima ili izraditi potpuno prilagoÄ‘enu listu.


## Stemizacija i lematizacija

Hrvatski jezik, kao i drugi slavenski jezici, ima bogatu morfologiju, Å¡to znaÄi da se ista rijeÄ pojavljuje u mnogim razliÄitim oblicima ovisno o gramatiÄkom kontekstu. Glagol "govoriti" moÅ¾e se pojaviti kao "govorim", "govoriÅ¡", "govori", "govorimo", "govorite", "govore", "govorio", "govorila", "govorili", "govorile", "govoreÄ‡i" i u brojnim drugim oblicima. Za analitiÄke svrhe, sve ove oblike poÅ¾eljno je tretirati kao razliÄite varijante iste temeljne konceptualne jedinice. Stemizacija i lematizacija dva su pristupa rjeÅ¡avanju ovog problema, pri Äemu oba teÅ¾e svoÄ‘enju razliÄitih oblika rijeÄi na zajedniÄki korijen. IstraÅ¾ivaÄ, ovisno o svojoj analitiÄkoj strategiji i dostupnim resursima, odabire jedan od ova dva pristupa.

Stemizacija predstavlja jednostavniji pristup koji koristi skup pravila za uklanjanje sufiksa i prefiksa s rijeÄi kako bi se dobio korijen ili stem. Rezultat stemizacije nije nuÅ¾no valjana rijeÄ u jeziku veÄ‡ oznaka koja sluÅ¾i za grupiranje srodnih oblika. Primjerice, stemizacija rijeÄi "ekonomski", "ekonomije" i "ekonomista" mogla bi proizvesti korijen "ekonom" koji nije samostalna hrvatska rijeÄ, ali sluÅ¾i kao zajedniÄki identifikator za sve tri izvorne rijeÄi.

Lematizacija, s druge strane, predstavlja sofisticiraniji pristup koji svodi rijeÄi na njihov kanonski oblik ili lemu, odnosno oblik koji bi se pronaÅ¡ao kao natuknica u rjeÄniku. Za imenice to je nominativ jednine, za glagole infinitiv, za pridjeve nominativ jednine muÅ¡kog roda. Za razliku od stemizacije, lematizacija uzima u obzir kontekst u kojem se rijeÄ javlja i njezinu gramatiÄku funkciju. Tako Ä‡e rijeÄ "bolje" biti ispravno svedena na lemu "dobar" kao komparativ pridjeva, dok bi stemizacija vjerojatno proizvela neupotrebljiv korijen poput "bolj".

@tbl-stem-lemma ilustrira razliku izmeÄ‘u stemizacije i lematizacije na konkretnim primjerima.

| Izvorni oblik | Rezultat stemizacije | Rezultat lematizacije | Napomena |
|:--------------|:---------------------|:----------------------|:---------|
| govorila | govor | govoriti | Glagol u proÅ¡lom vremenu |
| gospodarstva | gospodar | gospodarstvo | Imenica u genitivu |
| europskim | europs | europski | Pridjev u instrumentalu |
| bolje | bolj | dobar | Komparativ pridjeva |
| novinarka | novinar | novinarka | Imenica Å¾enskog roda |

: Usporedba stemizacije i lematizacije za odabrane rijeÄi {#tbl-stem-lemma}

Odluka izmeÄ‘u stemizacije i lematizacije ovisi o specifiÄnostima istraÅ¾ivaÄkog pitanja i dostupnim resursima. Stemizacija je raÄunalno uÄinkovitija i ne zahtijeva opseÅ¾ne lingvistiÄke resurse, Å¡to je Äini praktiÄnom za brzu obradu velikih korpusa. MeÄ‘utim, njezina agresivnost moÅ¾e rezultirati gubitkom semantiÄkih razlika. Lematizacija pruÅ¾a veÄ‡u preciznost i zadrÅ¾ava semantiÄku koherentnost, ali zahtijeva sofisticirane lingvistiÄke alate.

Za hrvatski jezik, stemizacijski algoritmi dostupni su u paketu SnowballC u R-u, dok se lematizacija moÅ¾e provesti pomoÄ‡u biblioteke udpipe koja podrÅ¾ava hrvatske jeziÄne modele. Python korisnici mogu koristiti classla biblioteku, specijaliziranu za juÅ¾noslavenske jezike (LjubeÅ¡iÄ‡ i Dobrovoljc, 2019).


## Izazovi specifiÄni za hrvatski jezik

Primjena metoda raÄunalne analize teksta na hrvatski jezik suoÄava se s nizom specifiÄnih izazova koji proizlaze iz lingvistiÄkih karakteristika hrvatskog i relativne oskudnosti dostupnih jeziÄnih resursa. Dok su alati i metode razvijene preteÅ¾no za engleski jezik dostigli visoku razinu sofisticiranosti, njihova prilagodba morfoloÅ¡ki bogatijim i resursno siromaÅ¡nijim jezicima poput hrvatskog ostaje aktivan istraÅ¾ivaÄki problem.

MorfoloÅ¡ka sloÅ¾enost hrvatskog jezika predstavlja prvi i najznaÄajniji izazov. Hrvatski pripada skupini slavenskih jezika s bogatom morfologijom, Å¡to znaÄi da imenice, pridjevi i zamjenice poznaju sedam padeÅ¾a u jednini i mnoÅ¾ini, dok glagoli variraju prema licu, broju, vremenu, naÄinu i vidu. Posljedica toga je da prosjeÄna hrvatska imenica ima oko Äetrnaest razliÄitih oblika (TadiÄ‡, 2003), dok glagoli mogu imati i preko stotinu oblika kada se ukljuÄe svi aspekti konjugacije. Ova morfoloÅ¡ka raznolikost drastiÄno poveÄ‡ava dimenzionalnost podataka i oteÅ¾ava prepoznavanje obrazaca.

Relativno slobodan redoslijed rijeÄi u hrvatskom predstavlja dodatnu komplikaciju za metode koje se oslanjaju na sekvencijalne obrasce poput analize n-grama. Dok u engleskom jeziku pozicija rijeÄi unutar reÄenice ima snaÅ¾nu gramatiÄku funkciju, u hrvatskom se ista informacija kodira morfoloÅ¡kim nastavcima, a redoslijed rijeÄi sluÅ¾i preteÅ¾no pragmatiÄkim i stilskim funkcijama. ReÄenice "Marko je vidio Anu", "Anu je vidio Marko" i "Vidio je Marko Anu" izraÅ¾avaju istu propoziciju, ali s razliÄitim informacijskim fokusom. To znaÄi da ista propozicija moÅ¾e biti izraÅ¾ena na viÅ¡e sintaktiÄki razliÄitih naÄina, Å¡to komplicira usporedbu tekstova i identifikaciju obrazaca.

Nedostatak lingvistiÄkih resursa za hrvatski jezik predstavlja praktiÄnu prepreku implementaciji sofisticiranih metoda analize. Dok za engleski jezik postoje opseÅ¾ne leksiÄke baze poput WordNeta s desecima tisuÄ‡a sinkroniziranih koncepata, validirani rjeÄnici sentimenata s desecima tisuÄ‡a oznaÄenih rijeÄi te napredni sustavi za morfoloÅ¡ku analizu, za hrvatski su takvi resursi znatno oskudniji. Hrvatski WordNet postoji, ali je manjeg opsega od engleskog originala. RjeÄnici sentimenata za hrvatski razvijaju se u akademskim projektima poput CroSentiLex (GlavaÅ¡, Karan i Å najder, 2012), no njihova pokrivenost i validacija variraju.

SpecifiÄnosti digitalnog registra hrvatskog jezika dodatno usloÅ¾njavaju analizu tekstova s druÅ¡tvenih mreÅ¾a i komentara na portalima. Korisnici Äesto koriste nestandardne oblike pisanja ukljuÄujuÄ‡i ispuÅ¡tanje dijakritiÄkih znakova, uporabu engleskih rijeÄi i fraza, regionalizme i Å¾argonizme te razne oblike kreativnog pravopisa. Tekst poput "neznam sta bi reko, bas mi je bed" ukljuÄuje viÅ¡e odstupanja od standardnog jezika koja algoritmi pripremljeni za standardni hrvatski neÄ‡e ispravno obraditi.

@tbl-izazovi-hr saÅ¾ima kljuÄne izazove hrvatskog jezika za raÄunalnu analizu teksta.

| Izazov | Opis problema | Implikacije za analizu |
|:-------|:--------------|:-----------------------|
| MorfoloÅ¡ka sloÅ¾enost | 7 padeÅ¾a, bogata konjugacija | Visoka dimenzionalnost, oteÅ¾ano grupiranje |
| Slobodan redoslijed rijeÄi | Gramatika kodirana morfemima | OgraniÄena korisnost sekvencijalnih metoda |
| Oskudica resursa | Manji leksikoni i alati | NiÅ¾a preciznost jeziÄnih alata |
| Digitalni registar | IspuÅ¡tanje dijakritika, anglizmi | Potrebna dodatna normalizacija |

: Izazovi primjene raÄunalne analize teksta na hrvatski jezik {#tbl-izazovi-hr}


## ÄŒiÅ¡Ä‡enje i normalizacija teksta

Sirovi tekst prikupljen iz digitalnih izvora gotovo uvijek sadrÅ¾i elemente koji nisu relevantni za sadrÅ¾ajnu analizu, a mogu ometati rad analitiÄkih alata ili iskriviti rezultate. ÄŒiÅ¡Ä‡enje teksta obuhvaÄ‡a skup postupaka kojima se uklanjaju takvi neÅ¾eljeni elementi i standardizira format podataka. Premda se moÅ¾e Äiniti tehniÄkim i rutinskim, ovaj korak zahtijeva paÅ¾ljivo razmatranje jer svaka odluka o uklanjanju ili transformaciji utjeÄe na konaÄnu analizu.

Uklanjanje interpunkcije jedan je od najÄeÅ¡Ä‡ih koraka ÄiÅ¡Ä‡enja. ToÄke, zarezi, upitnici i drugi interpunkcijski znakovi obiÄno ne nose semantiÄku informaciju relevantnu za analizu sadrÅ¾aja te se rutinski uklanjaju. MeÄ‘utim, postoje konteksti u kojima interpunkcija moÅ¾e biti znaÄajna. U analizi emocionalnog intenziteta viÅ¡estruki uskliÄnici ili upitnici mogu signalizirati pojaÄanu emocionalnu angaÅ¾iranost autora, pa bi njihovo uklanjanje znaÄilo gubitak relevantne informacije.

Tekstovi prikupljeni s interneta Äesto sadrÅ¾e HTML oznake, URL adrese i posebne znakove koji su relevantni za prikaz teksta u pregledniku, ali nemaju sadrÅ¾ajnu vrijednost. Uklanjanje takvih elemenata dio je standardnog protokola ÄiÅ¡Ä‡enja. Posebnu paÅ¾nju zahtijevaju emotikoni i emojiji koji su sve prisutniji u tekstovima digitalnih medija. Iako nemaju leksiÄko znaÄenje u tradicionalnom smislu, emojiji Äesto nose znaÄajnu emocionalnu informaciju i mogu biti relevantni za odreÄ‘ene tipove analize poput analize sentimenata.

Normalizacija dijakritika specifiÄan je izazov za hrvatski jezik. Korisnici digitalnih medija Äesto ispuÅ¡taju dijakritiÄke znakove piÅ¡uÄ‡i "zasto" umjesto "zaÅ¡to" ili "covjek" umjesto "Äovjek". IstraÅ¾ivaÄ moÅ¾e odluÄiti normalizirati takve oblike na standardnu ortografiju ili pak zadrÅ¾ati nestandardne oblike kao indikator registra ili sociolingvistiÄkih karakteristika autora. Prva opcija pojednostavljuje analizu dok druga zadrÅ¾ava potencijalno relevantnu informaciju.

Protokol ÄiÅ¡Ä‡enja teksta tipiÄno obuhvaÄ‡a sljedeÄ‡e korake: pretvaranje teksta u mala slova, uklanjanje HTML oznaka i URL adresa, uklanjanje ili zamjena posebnih znakova, normalizacija razmaka i uklanjanje viÅ¡estrukih razmaka, te opcionalno normalizacija dijakritika i uklanjanje brojeva. U R-u, paket quanteda integrira veÄ‡inu ovih koraka u funkciju `tokens()`, dok se specifiÄniji zahvati poput normalizacije dijakritika mogu provesti pomoÄ‡u regularnih izraza.


## SaÅ¾etak pripreme podataka

Kao Å¡to je u ovom poglavlju prikazano, priprema podataka za raÄunalnu analizu teksta obavlja se kroz Äetiri temeljne faze: tokenizaciju, uklanjanje zaustavnih rijeÄi, stemizaciju ili lematizaciju te ÄiÅ¡Ä‡enje i normalizaciju teksta. Svaki od ovih koraka ukljuÄuje analitiÄke odluke koje izravno utjeÄu na konaÄne rezultate.

U praktiÄnom smislu, priprema podataka zapoÄinje uÄitavanjem sirovih tekstualnih podataka u analitiÄko okruÅ¾enje. Analogno tome kako se u klasiÄnom kvantitativnom istraÅ¾ivanju najprije izradi baza podataka u tabliÄnom obliku (primjerice u Excelu), u kojoj se podaci strukturiraju kao kombinacija varijabli i sluÄajeva, te se potom ta baza uÄita u statistiÄki program (poput SPSS-a), u raÄunalnoj analizi teksta sirovi se tekstovi najprije organiziraju u korpus. Korpus je strukturirana zbirka tekstova u kojoj svaki dokument predstavlja jedan sluÄaj, a uz njega se mogu vezati metapodaci (datum objave, izvor, autor i sliÄno) koji funkcioniraju kao varijable. Izrada korpusa i svi koraci pripreme obavljaju se u programskom okruÅ¾enju poput R-a, gdje paket quanteda nudi integrirani radni tijek od uÄitavanja podataka do gotove matrice dokument-termin.

@tbl-priprema prikazuje pregled koraka pripreme podataka i njihovih implikacija za analizu.

| Korak | Svrha | Potencijalni gubitak informacija |
|:------|:------|:---------------------------------|
| Tokenizacija | RaÅ¡Älamba teksta na analitiÄke jedinice | Gubitak informacija o sekvencijalnim odnosima |
| Uklanjanje stop-rijeÄi | Redukcija Å¡uma i dimenzionalnosti | Gubitak gramatiÄkih i pragmatiÄkih signala |
| Lematizacija/stemizacija | SvoÄ‘enje na korijenske oblike | Gubitak morfoloÅ¡kih distinkcija |
| ÄŒiÅ¡Ä‡enje i normalizacija | Standardizacija formata | Gubitak stilistiÄkih i registarskih signala |

: Pregled koraka pripreme podataka i njihovih implikacija za analizu {#tbl-priprema}

Postupak pripreme podataka moÅ¾e se konceptualizirati kao serija transformacija koje sirovi tekst prevode u strukturirani oblik spreman za analizu. Svaki korak ukljuÄuje implicitne i eksplicitne odluke o tome Å¡to je relevantno za istraÅ¾ivanje, a Å¡to predstavlja Å¡um koji treba ukloniti. Kvaliteta pripreme podataka izravno utjeÄe na valjanost rezultata, a transparentnost u dokumentiranju primijenjenih postupaka nuÅ¾an je preduvjet znanstvene ponovljivosti. IstraÅ¾ivaÄ koji razumije logiku i implikacije svakoga koraka u procesu pripreme moÅ¾e donijeti informirane odluke koje optimalno sluÅ¾e specifiÄnom istraÅ¾ivaÄkom pitanju.


# Reprezentacija teksta

Nakon Å¡to su podaci pripremljeni i sreÄ‘eni, iduÄ‡i korak u provedbi raÄunalne analize teksta jest pretvaranje tekstualnih podataka u oblik koji Ä‡e omoguÄ‡iti sustavnu usporedbu i statistiÄku analizu. Taj se postupak naziva reprezentacija teksta i u njemu se tekstualni podaci transformiraju u matematiÄke strukture, najÄeÅ¡Ä‡e vektore ili matrice, pogodne za raÄunalnu obradu.

Zamislimo istraÅ¾ivaÄa koji Å¾eli usporediti kako tri vodeÄ‡a hrvatska informativna portala izvjeÅ¡tavaju o klimatskim promjenama. Na raspolaganju mu je korpus od nekoliko tisuÄ‡a Älanaka prikupljenih tijekom jednogodiÅ¡njeg razdoblja. Nakon Å¡to je proveo tokenizaciju, uklonio zaustavne rijeÄi i normalizirao tekst, suoÄava se s temeljnim pitanjem: kako pretvoriti ove tekstualne podatke u oblik koji Ä‡e omoguÄ‡iti sustavnu usporedbu? Kako reprezentirati tekst na naÄin koji Ä‡e raÄunalu omoguÄ‡iti prepoznavanje sliÄnosti i razlika izmeÄ‘u dokumenata, identificiranje karakteristiÄnih tema za svaki portal te otkrivanje obrazaca u medijskom diskursu?

Reprezentacija teksta kljuÄan je korak jer njezina kvaliteta izravno utjeÄe na uspjeÅ¡nost svih naknadnih analitiÄkih postupaka. LoÅ¡e odabrana reprezentacija moÅ¾e prikriti relevantne obrasce ili, suprotno, proizvesti artefakte koji ne odraÅ¾avaju stvarne karakteristike teksta. U programskom okruÅ¾enju, reprezentacija teksta obavlja se transformacijom tokeniziranog teksta u numeriÄku matricu pomoÄ‡u alata poput funkcije `dfm()` u paketu quanteda.

Temeljni izazov reprezentacije teksta proizlazi iz fundamentalne razlike izmeÄ‘u prirode jezika i zahtjeva kvantitativnih metoda. Jezik je semantiÄki bogat, kontekstualno ovisan i viÅ¡eznaÄan sustav u kojem znaÄenje proizlazi iz sloÅ¾enih odnosa izmeÄ‘u rijeÄi, reÄenica i Å¡ireg diskursnog konteksta. S druge strane, statistiÄki algoritmi zahtijevaju precizno definirane numeriÄke vrijednosti organizirane u pravilne strukture. Svaka reprezentacija stoga nuÅ¾no ukljuÄuje odreÄ‘enu razinu pojednostavljenja i gubitka informacija, a zadatak istraÅ¾ivaÄa jest odabrati pristup koji optimalno balansira izmeÄ‘u raÄunalne uÄinkovitosti i oÄuvanja semantiÄki relevantnih svojstava teksta.

U nastavku se razmatraju tri temeljna modela reprezentacije teksta: model vreÄ‡e rijeÄi, TF-IDF vaganje te matrica supojavljivanja. Svaki od ovih modela nudi drugaÄiju perspektivu na tekstualne podatke i odgovara na razliÄite analitiÄke potrebe.


## Model vreÄ‡e rijeÄi

Model vreÄ‡e rijeÄi, poznat i pod engleskim nazivom *Bag-of-Words* ili skraÄ‡enicom BoW, predstavlja najjednostavniji i povijesno najraniji pristup reprezentaciji teksta za kvantitativnu analizu. Osnovna pretpostavka ovog modela jest da se sadrÅ¾aj dokumenta moÅ¾e aproksimirati jednostavnim prebrojavanjem rijeÄi koje se u njemu pojavljuju, pri Äemu se potpuno zanemaruje redoslijed rijeÄi i gramatiÄka struktura.

Premda se ova pretpostavka moÅ¾e Äiniti drastiÄnim pojednostavljenjem, praksa je pokazala da za mnoge analitiÄke zadatke takva reprezentacija pruÅ¾a iznenaÄ‘ujuÄ‡e dobre rezultate. Ako je cilj klasificirati novinarske Älanke prema temama, Äinjenica da Älanak sadrÅ¾i rijeÄi poput "inflacija", "kamatna stopa", "BDP" i "proraÄun" snaÅ¾no sugerira da se radi o ekonomskoj tematici, neovisno o tome kojim redoslijedom se te rijeÄi pojavljuju u tekstu. SliÄno tome, visoka frekvencija rijeÄi poput "utakmica", "gol", "prvak" i "reprezentacija" pouzdano identificira sportski sadrÅ¾aj.

Formalno, model vreÄ‡e rijeÄi reprezentira korpus dokumenata pomoÄ‡u matrice dokument-termin. Radi se o matrici u kojoj svaki redak predstavlja jedan dokument, svaki stupac predstavlja jednu jedinstvenu rijeÄ iz cjelokupnog vokabulara korpusa, a vrijednost u svakoj Ä‡eliji oznaÄava frekvenciju pojavljivanja te rijeÄi u tom dokumentu.

Zamislimo konkretan primjer s tri kratka naslova novinskih Älanaka: "Vlada najavljuje nove porezne reforme", "Premijer najavljuje reforme zdravstvenog sustava" i "Nove mjere za poticanje gospodarstva". Matrica dokument-termin za ovaj mini-korpus prikazana je u @tbl-dtm.

| Dokument | vlada | najavljuje | nove | porezne | reforme | premijer | zdravstvenog | sustava | mjere | poticanje | gospodarstva |
|:---------|:-----:|:----------:|:----:|:-------:|:-------:|:--------:|:------------:|:-------:|:-----:|:---------:|:------------:|
| D1 | 1 | 1 | 1 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 |
| D2 | 0 | 1 | 0 | 0 | 1 | 1 | 1 | 1 | 0 | 0 | 0 |
| D3 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 1 |

: Primjer matrice dokument-termin za tri kratka dokumenta {#tbl-dtm}

Iz ove matrice moÅ¾e se vidjeti da dokumenti D1 i D2 dijele dvije rijeÄi ("najavljuje" i "reforme"), dok D3 nema zajedniÄkih rijeÄi s ostala dva dokumenta osim pridjeva "nove" koji dijeli s D1. Ova informacija moÅ¾e posluÅ¾iti za kvantifikaciju sliÄnosti izmeÄ‘u dokumenata, primjerice koriÅ¡tenjem kosinusne sliÄnosti ili drugih mjera udaljenosti u vektorskom prostoru.

Model vreÄ‡e rijeÄi ima nekoliko znaÄajnih ograniÄenja koja valja imati na umu. BuduÄ‡i da se potpuno zanemaruje redoslijed rijeÄi, reÄenice "Marko voli Anu" i "Ana voli Marka" imaju identiÄnu reprezentaciju premda izraÅ¾avaju razliÄite propozicije. SliÄno tome, reÄenica "Film nije bio dosadan" i "Film je bio dosadan" imaju gotovo identiÄnu reprezentaciju jer se razlikuju samo u jednoj rijeÄi, premda izraÅ¾avaju suprotne evaluacije. Ova ograniÄenja motiviraju razvoj sofisticiranijih metoda reprezentacije.


## TF-IDF: vaganje vaÅ¾nosti rijeÄi

Jednostavno prebrojavanje rijeÄi, kako ga provodi model vreÄ‡e rijeÄi, tretira sve rijeÄi kao jednako vaÅ¾ne. MeÄ‘utim, intuitivno je jasno da sve rijeÄi ne nose jednaku koliÄinu informacija. RijeÄ koja se pojavljuje u gotovo svakom dokumentu korpusa, poput veznika "i" ili glagola "je", govori vrlo malo o sadrÅ¾aju specifiÄnog dokumenta. S druge strane, rijeÄ koja se pojavljuje samo u malom broju dokumenata moÅ¾e biti kljuÄna za razumijevanje njihove specifiÄnosti. Primjerice, rijeÄ "fotonaponski" u korpusu ekonomskih vijesti vjerojatno se pojavljuje samo u Älancima o obnovljivim izvorima energije i kao takva je visoko informativna za identificiranje te podteme.

TF-IDF, skraÄ‡enica od *term frequency-inverse document frequency*, jest statistiÄka mjera koja pokuÅ¡ava uhvatiti ovu intuiciju dodjeljivanjem veÄ‡e teÅ¾ine rijeÄima koje su karakteristiÄne za pojedine dokumente, a manje teÅ¾ine rijeÄima koje su uobiÄajene u cijelom korpusu. Mjera je osmiÅ¡ljena sredinom dvadesetog stoljeÄ‡a u kontekstu informacijskog pretraÅ¾ivanja (Sparck Jones, 1972), ali je postala standardni alat u Å¡irokom rasponu primjena raÄunalne analize teksta.

Logika TF-IDF mjere temelji se na dva komponenta. Prvi komponenta, frekvencija termina (TF), jednostavno mjeri koliko se Äesto odreÄ‘ena rijeÄ pojavljuje u dokumentu, izraÅ¾avajuÄ‡i se kao relativna frekvencija (omjer broja pojavljivanja i ukupnog broja rijeÄi). Formalno:

$$TF(t, d) = \frac{f_{t,d}}{\sum_{t' \in d} f_{t',d}}$$

Drugi komponenta, inverzna frekvencija dokumenta (IDF), mjeri koliko je rijeÄ rijetka ili Äesta u cijelom korpusu, pri Äemu se rijetkim rijeÄima pridaje veÄ‡a teÅ¾ina:

$$IDF(t, D) = \ln\left(\frac{N}{|\{d \in D : t \in d\}|}\right)$$

KonaÄna TF-IDF vrijednost dobiva se mnoÅ¾enjem ova dva komponenta:

$$TF\text{-}IDF(t, d, D) = TF(t, d) \times IDF(t, D)$$

Rezultat ove mjere jest da rijeÄ koja se Äesto pojavljuje u jednom dokumentu, ali rijetko u ostalima, ima visoku vrijednost jer su oba faktora visoka. RijeÄ koja se pojavljuje u svim dokumentima automatski se neutralizira jer njezina inverzna frekvencija dokumenta postaje nula.

@tbl-tfidf prikazuje hipotetski primjer TF-IDF vrijednosti za odabrane rijeÄi u tri dokumenta o ekonomskoj tematici.

| RijeÄ | D1 (Fiskalna politika) | D2 (Monetarna politika) | D3 (OpÄ‡i pregled) |
|:------|:----------------------:|:-----------------------:|:-----------------:|
| proraÄun | 0.089 | 0.012 | 0.031 |
| deficit | 0.076 | 0.008 | 0.022 |
| kamatna | 0.011 | 0.094 | 0.028 |
| inflacija | 0.023 | 0.081 | 0.035 |
| gospodarstvo | 0.018 | 0.021 | 0.019 |

: Hipotetske TF-IDF vrijednosti za odabrane rijeÄi u tri ekonomska teksta {#tbl-tfidf}

Iz tablice je vidljivo da rijeÄi "proraÄun" i "deficit" imaju najviÅ¡e vrijednosti u dokumentu D1 koji se bavi fiskalnom politikom, dok "kamatna" i "inflacija" dominiraju u D2 o monetarnoj politici. RijeÄ "gospodarstvo" ima sliÄne, relativno niske vrijednosti u sva tri dokumenta jer se pojavljuje u svima i nema diskriminacijsku snagu.

U R-u, TF-IDF vaganje primjenjuje se na matricu dokument-termin jednom naredbom u paketu quanteda.


## Matrica supojavljivanja

Prethodno razmatrane metode reprezentacije fokusirale su se na odnos izmeÄ‘u rijeÄi i dokumenata, tretirajuÄ‡i svaku rijeÄ kao nezavisnu jedinicu. MeÄ‘utim, znaÄenje rijeÄi u prirodnom jeziku uvelike ovisi o kontekstu u kojem se pojavljuje i o drugim rijeÄima s kojima se redovito javlja zajedno. LingvistiÄka hipoteza distribucijske semantike, koju je formulirao Zellig Harris sredinom dvadesetog stoljeÄ‡a (Harris, 1954), tvrdi da rijeÄi koje se pojavljuju u sliÄnim kontekstima imaju sliÄna znaÄenja. Ova intuicija motivira pristup reprezentaciji teksta temeljen na analizi supojavljivanja rijeÄi.

Matrica supojavljivanja biljeÅ¾i koliko se Äesto parovi rijeÄi pojavljuju zajedno unutar definiranog kontekstualnog prozora. Za razliku od matrice dokument-termin gdje redci predstavljaju dokumente, u matrici supojavljivanja i redci i stupci predstavljaju rijeÄi iz vokabulara. Vrijednost u Ä‡eliji oznaÄava koliko se puta jedna rijeÄ pojavila u neposrednoj blizini druge u cijelom korpusu. VeliÄina kontekstualnog prozora, najÄeÅ¡Ä‡e definirana kao odreÄ‘eni broj rijeÄi prije i poslije ciljne rijeÄi, parametar je koji istraÅ¾ivaÄ odreÄ‘uje ovisno o analitiÄkim ciljevima.

Zamislimo da se analizira korpus novinskih Älanaka o hrvatskom turizmu i definira kontekstualni prozor od dvije rijeÄi s obje strane. Ako se u tekstu Äesto pojavljuju fraze poput "turistiÄka sezona", "ljetna sezona", "zimska sezona", matrica supojavljivanja Ä‡e zabiljeÅ¾iti visoke vrijednosti za parove (turistiÄka, sezona), (ljetna, sezona) i (zimska, sezona).

@tbl-cooccur prikazuje hipotetski isjeÄak matrice supojavljivanja za mali skup rijeÄi iz korpusa o ekonomiji.

| | rast | pad | gospodarstvo | inflacija | plaÄ‡e |
|:------------|:----:|:---:|:------------:|:---------:|:-----:|
| rast | - | 12 | 87 | 23 | 45 |
| pad | 12 | - | 65 | 34 | 38 |
| gospodarstvo | 87 | 65 | - | 41 | 52 |
| inflacija | 23 | 34 | 41 | - | 28 |
| plaÄ‡e | 45 | 38 | 52 | 28 | - |

: Hipotetski isjeÄak matrice supojavljivanja za ekonomski vokabular {#tbl-cooccur}

Iz tablice se moÅ¾e iÅ¡Äitati da se "rast" i "gospodarstvo" vrlo Äesto pojavljuju zajedno (87 supojavljivanja), dok "rast" i "pad" supostoje znatno rjeÄ‘e (12), Å¡to je oÄekivano jer se radi o antonimima koji se rijetko koriste u istom kontekstu. RijeÄ "gospodarstvo" ima visoke vrijednosti supojavljivanja sa svim ostalim rijeÄima jer je to opÄ‡eniti termin koji se prirodno kombinira s raznim ekonomskim konceptima.

KljuÄna prednost matrice supojavljivanja jest Å¡to omoguÄ‡uje otkrivanje semantiÄkih odnosa izmeÄ‘u rijeÄi. RijeÄi koje se pojavljuju u sliÄnim kontekstima imaju sliÄne profile supojavljivanja, Å¡to omoguÄ‡uje mjerenje semantiÄke sliÄnosti usporedbom njihovih vektora. U R-u, matrica supojavljivanja izraÄ‘uje se pomoÄ‡u funkcije `fcm()` u paketu quanteda.

@tbl-reprezentacija pruÅ¾a usporedni pregled triju metoda reprezentacije teksta.

| Metoda | Struktura | Å to mjeri | TipiÄna primjena |
|:-------|:----------|:----------|:-----------------|
| VreÄ‡a rijeÄi (BoW) | Matrica dokument-termin | Frekvencija rijeÄi u dokumentima | Klasifikacija dokumenata, pretraÅ¾ivanje |
| TF-IDF | Matrica dokument-termin s teÅ¾inama | VaÅ¾nost rijeÄi za dokument u korpusu | Identificiranje kljuÄnih termina, usporedba dokumenata |
| Matrica supojavljivanja | Matrica rijeÄ-rijeÄ | Kontekstualna bliskost rijeÄi | SemantiÄka analiza, analiza diskursa |

: Usporedba metoda reprezentacije teksta {#tbl-reprezentacija}

RazliÄite metode reprezentacije teksta nude komplementarne perspektive na tekstualne podatke. Model vreÄ‡e rijeÄi pruÅ¾a jednostavan i robustan temelj za mnoge analitiÄke zadatke, posebno za klasifikaciju dokumenata. TF-IDF nadograÄ‘uje taj temelj uvoÄ‘enjem koncepta teÅ¾ina koje reflektiraju diskriminacijsku vrijednost rijeÄi. Matrica supojavljivanja otvara prozor u semantiÄke odnose koji definiraju znaÄenje rijeÄi u kontekstu.

U praksi, izbor metode reprezentacije ovisi o specifiÄnostima istraÅ¾ivaÄkog pitanja, karakteristikama korpusa i raÄunalnim resursima. Za jednostavne klasifikacijske zadatke na velikim korpusima, TF-IDF reprezentacija Äesto predstavlja optimalan balans izmeÄ‘u informativnosti i raÄunalne uÄinkovitosti. Za eksplorativne analize semantiÄkih odnosa i diskurzivnih obrazaca, matrica supojavljivanja moÅ¾e pruÅ¾iti bogatije uvide.

Napredak u dubokom uÄenju donio je nove pristupe reprezentaciji teksta koji nadilaze jednostavne statistiÄke mjere. Vektorske reprezentacije rijeÄi (*word embeddings*) poput Word2Vec ili GloVe uÄe guste vektorske reprezentacije iz velikih korpusa, zahvaÄ‡ajuÄ‡i semantiÄke odnose na naÄin koji omoguÄ‡uje aritmetiÄke operacije nad znaÄenjima. JoÅ¡ napredniji pristup predstavljaju kontekstualizirane reprezentacije temeljene na transformerima (BERT, GPT) koje generiraju reprezentacije ovisne o kontekstu, tako da ista rijeÄ dobiva razliÄitu reprezentaciju ovisno o reÄenici u kojoj se pojavljuje. Ovi pristupi postiÅ¾u impresivne rezultate na Å¡irokom rasponu zadataka, ali zahtijevaju znaÄajne raÄunalne resurse i specijalizirano znanje.


# Vrste analize teksta

Nakon Å¡to su razmotreni postupci pripreme podataka i metode reprezentacije teksta, dolazi se do kljuÄnog pitanja: kako iz pripremljenih tekstualnih podataka izvuÄ‡i smislene zakljuÄke koji Ä‡e odgovoriti na istraÅ¾ivaÄka pitanja? Odgovor ovisi o prirodi problema koji se Å¾eli rijeÅ¡iti i o vrsti znanja koje se nastoji generirati. IstraÅ¾ivaÄ masovne komunikacije moÅ¾e biti zainteresiran za automatsku klasifikaciju velikog broja Älanaka prema temama, za otkrivanje skrivenih tematskih struktura u korpusu, za mjerenje emocionalnog tona medijskog izvjeÅ¡tavanja ili za identificiranje kljuÄnih aktera u javnom diskursu. Svaki od ovih zadataka zahtijeva drugaÄiji analitiÄki pristup, a izbor metode ima dalekoseÅ¾ne implikacije za vrstu uvida koje je moguÄ‡e dobiti.

U ovom se poglavlju predstavljaju Äetiri temeljne vrste analize teksta koje se razlikuju prema logici zakljuÄivanja, potrebnim resursima i vrstama pitanja na koja mogu odgovoriti. Nadzirano strojno uÄenje koristi unaprijed oznaÄene primjere za treniranje modela koji klasificira nove tekstove u poznate kategorije. Nenadzirano strojno uÄenje (tematsko modeliranje) otkriva latentne strukture u podacima bez prethodnog definiranja kategorija. RjeÄniÄki pristupi (analiza sentimenta) oslanjaju se na unaprijed definirane popise rijeÄi s pridruÅ¾enim vrijednostima za mjerenje specifiÄnih dimenzija teksta. Ekstrakcija entiteta identificira i klasificira imena osoba, organizacija i lokacija u tekstu.


## Nadzirano strojno uÄenje

Zamislimo istraÅ¾ivaÄa koji analizira tisuÄ‡e komentara objavljenih na druÅ¡tvenim mreÅ¾ama tijekom predizborne kampanje. Cilj je kategorizirati svaki komentar prema tome podrÅ¾ava li odreÄ‘enog kandidata, kritizira ga ili je neutralan. RuÄno kodiranje tolikog broja komentara zahtijevalo bi mjesece rada i znaÄajne financijske resurse. Nadzirano strojno uÄenje nudi alternativu: istraÅ¾ivaÄ ruÄno kodira relativno mali uzorak komentara, a zatim koristi te oznaÄene primjere za treniranje algoritma koji Ä‡e automatski klasificirati preostale komentare. Na taj se naÄin kombiniraju prednosti ljudske prosudbe s raÄunalnom uÄinkovitoÅ¡Ä‡u.

Proces nadziranog uÄenja zapoÄinje s ruÄnim oznaÄavanjem skupa dokumenata prema kategorijama od interesa. Ovaj oznaÄeni skup dijeli se na trenaÅ¾ni skup, koji sluÅ¾i za uÄenje algoritma, i testni skup, koji sluÅ¾i za evaluaciju performansi. Algoritam analizira karakteristike dokumenata u trenaÅ¾nom skupu, tipiÄno njihovu vektorsku reprezentaciju temeljenu na frekvencijama rijeÄi, i uÄi pravila koja povezuju te karakteristike s kategorijama. NauÄena pravila potom se primjenjuju na testni skup, a usporedba predikcija algoritma s pravim oznakama pruÅ¾a objektivnu mjeru uspjeÅ¡nosti.

Evaluacija klasifikatora oslanja se na standardne mjere koje kvantificiraju razliÄite aspekte performansi:

**ToÄnost** (*accuracy*) mjeri udio ispravno klasificiranih dokumenata:

$$\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$$

**Preciznost** (*precision*) mjeri pouzdanost pozitivnih predikcija:

$$\text{Precision} = \frac{TP}{TP + FP}$$

**Odziv** (*recall*) mjeri sposobnost prepoznavanja svih pozitivnih sluÄajeva:

$$\text{Recall} = \frac{TP}{TP + FN}$$

**F1 mjera** predstavlja harmonijsku sredinu preciznosti i odziva:

$$F_1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}$$

@tbl-evaluacija ilustrira interpretaciju ovih mjera na primjeru klasifikacije komentara.

| Metrika | Formula | Interpretacija u kontekstu | TipiÄna vrijednost |
|:--------|:--------|:---------------------------|:-------------------|
| ToÄnost | (TP+TN)/(TP+TN+FP+FN) | Udio ispravno klasificiranih komentara | 0.70-0.90 |
| Preciznost | TP/(TP+FP) | Pouzdanost kada model kaÅ¾e "pozitivan" | 0.60-0.85 |
| Odziv | TP/(TP+FN) | Koliko pozitivnih komentara model pronalazi | 0.60-0.85 |
| F1 | Harmonijska sredina P i R | UravnoteÅ¾ena mjera performansi | 0.65-0.85 |

: Evaluacijske metrike za nadzirano uÄenje {#tbl-evaluacija}

MeÄ‘u algoritmima nadziranog uÄenja koji se primjenjuju na tekstualne podatke, logistiÄka regresija, Naive Bayes i Support Vector Machines (SVM) predstavljaju klasiÄne pristupe koji se i dalje Å¡iroko koriste. LogistiÄka regresija modelira vjerojatnost pripadnosti kategoriji kao funkciju kombinacije znaÄajki, nudeÄ‡i interpretabilne koeficijente koji pokazuju doprinos svake rijeÄi klasifikaciji. Naive Bayes temelji se na Bayesovom teoremu uz pretpostavku nezavisnosti znaÄajki. SVM traÅ¾i granicu koja maksimalno razdvaja kategorije u prostoru znaÄajki.

PraktiÄna primjena nadziranog uÄenja u istraÅ¾ivanju masovne komunikacije moÅ¾e se ilustrirati primjerom klasifikacije vijesti prema temama na hrvatskim portalima. IstraÅ¾ivaÄ zapoÄinje definiranjem kategorijalne sheme, primjerice: politika, gospodarstvo, sport, kultura, crna kronika. Zatim nasumiÄno odabire uzorak od nekoliko stotina Älanaka koje ruÄno kodira prema definiranim kategorijama. Ovaj oznaÄeni skup predstavlja "zlatni standard" na temelju kojega Ä‡e algoritam uÄiti. KritiÄno je osigurati da su kategorije jasno definirane i meÄ‘usobno iskljuÄive te da viÅ¡e kodiraÄa postiÅ¾e visoku razinu slaganja kako bi se osigurala pouzdanost oznaka.

Nakon oznaÄavanja, tekstualne podatke treba transformirati u numeriÄku reprezentaciju. NajÄeÅ¡Ä‡i pristup koristi TF-IDF vrijednosti rijeÄi kao znaÄajke, stvarajuÄ‡i visokodimenzionalni vektor za svaki dokument. Algoritam zatim uÄi statistiÄke obrasce koji povezuju ove vektorske reprezentacije s kategorijama.

KljuÄno metodoloÅ¡ko pitanje jest kako podijeliti podatke za treniranje i evaluaciju. Standardni pristup koristi unakrsnu validaciju (*cross-validation*) gdje se podaci dijele na *k* podskupova, a model se trenira *k* puta, svaki put koristeÄ‡i razliÄiti podskup za testiranje. Za vremenski strukturirane podatke poput novinarskih Älanaka, preporuÄuje se koriÅ¡tenje temporalne validacije gdje se model trenira na starijim Älancima i testira na novijima, Å¡to bolje simulira stvarnu primjenu.

U R-u, nadzirano uÄenje na tekstualnim podacima provodi se kombinacijom paketa quanteda za pripremu podataka i quanteda.textmodels ili caret za treniranje klasifikatora.


## Tematsko modeliranje: Latent Dirichlet Allocation

Za razliku od nadziranog uÄenja koje zahtijeva unaprijed definirane kategorije, tematsko modeliranje pripada skupini nenadziranih metoda koje otkrivaju latentne strukture u podacima bez prethodne specifikacije. Najutjecajniji pristup tematskom modeliranju jest *Latent Dirichlet Allocation* (LDA), statistiÄki model razvijen poÄetkom dvadeset i prvog stoljeÄ‡a (Blei, Ng i Jordan, 2003) koji pretpostavlja da je svaki dokument mjeÅ¡avina nekoliko apstraktnih tema, a svaka tema karakterizirana distribucijom preko rijeÄi.

Intuicija iza LDA modela moÅ¾e se ilustrirati primjerom iz novinarstva. Zamislimo Älanak na temu klimatskih promjena i energetske politike. Takav Älanak vjerojatno sadrÅ¾i rijeÄi iz razliÄitih tematskih domena: rijeÄi vezane uz klimu poput "temperatura", "emisije", "ugljik", rijeÄi vezane uz energetiku poput "elektrane", "obnovljivi", "fosilna" te rijeÄi vezane uz politiku poput "zakon", "regulativa", "vlada". LDA formalno modelira ovu intuiciju pretpostavljajuÄ‡i da autor dokumenta implicitno odabire mjeÅ¡avinu tema, a zatim za svaku rijeÄ u dokumentu odabire jednu od tema i generira rijeÄ prema distribuciji te teme.

MatematiÄki gledano, LDA je probabilistiÄki model koji koristi statistiÄke distribucije za opisivanje procesa nastanka dokumenata. Za dokument $d$, distribucija tema $\theta_d$ generira se iz Dirichletove distribucije:

$$\theta_d \sim \text{Dirichlet}(\alpha)$$

Za svaku temu $k$, distribucija rijeÄi $\phi_k$ takoÄ‘er se generira iz Dirichletove distribucije:

$$\phi_k \sim \text{Dirichlet}(\beta)$$

U praktiÄnom smislu, model analizira koje se rijeÄi pojavljuju zajedno u istim dokumentima i na temelju tih obrazaca identificira grupe rijeÄi koje Äine koherentne "teme". Ono Å¡to Äini LDA posebno korisnim jest Å¡to model dopuÅ¡ta da svaki dokument pripada viÅ¡e tema istovremeno, Å¡to odraÅ¾ava stvarnost medijskih tekstova koji rijetko pokrivaju samo jednu temu.

@tbl-lda prikazuje hipotetski primjer rezultata LDA analize na korpusu hrvatskih politiÄkih vijesti.

| Tema | KarakteristiÄne rijeÄi | Interpretacija |
|:-----|:-----------------------|:---------------|
| Tema 1 | proraÄun, deficit, porez, prihod, rashod | Fiskalna politika |
| Tema 2 | EU, Bruxelles, komisija, fond, Älanica | Europska politika |
| Tema 3 | Å¡kola, uÄenik, nastavnik, obrazovanje, reforma | Obrazovna politika |
| Tema 4 | bolnica, lijeÄnik, pacijent, zdravstvo, lista | Zdravstvena politika |
| Tema 5 | izbori, stranka, kandidat, glasaÄ, kampanja | Izborna politika |

: Primjer rezultata LDA analize na korpusu politiÄkih vijesti {#tbl-lda}

PraktiÄna primjena LDA modela zahtijeva donoÅ¡enje nekoliko kljuÄnih odluka. IstraÅ¾ivaÄ mora odrediti broj tema $k$ koji nije poznat unaprijed. Premali broj tema rezultira preÅ¡irokim, heterogenim temama, dok prevelik broj moÅ¾e fragmentirati koherentne teme i proizvesti teme koje je teÅ¡ko interpretirati. Ne postoji objektivno ispravna vrijednost jer optimalan broj ovisi o karakteristikama korpusa i istraÅ¾ivaÄkim ciljevima. U praksi se Äesto eksperimentira s razliÄitim vrijednostima i kombinira kvantitativne mjere poput koherentnosti tema s kvalitativnom procjenom interpretabilnosti.

Interpretacija tema zahtijeva paÅ¾ljivu analizu distribucija rijeÄi. Za svaku temu, istraÅ¾ivaÄ pregledava najvjerojatnije rijeÄi i pokuÅ¡ava identificirati koherentni koncept koji ih povezuje. Ovaj proces zahtijeva domensko znanje i kontekstualno razumijevanje. Primjerice, tema s rijeÄima "bolnica", "lijeÄnik", "pacijent", "zdravstvo" intuitivno sugerira zdravstvenu politiku. MeÄ‘utim, tema s rijeÄima "projekt", "sredstva", "program", "provedba" mogla bi se odnositi na razliÄite domene ovisno o Å¡irem kontekstu korpusa.

Za istraÅ¾ivanje masovne komunikacije, LDA omoguÄ‡uje praÄ‡enje tematske strukture medijskog prostora kroz vrijeme. MoguÄ‡e je analizirati kako se zastupljenost pojedinih tema mijenja, identificirati dogaÄ‘aje koji su potaknuli porast odreÄ‘enih tema ili usporediti tematski fokus razliÄitih medija.

Valja napomenuti i ograniÄenja LDA modela. Model pretpostavlja da su dokumenti vreÄ‡e rijeÄi, zanemarujuÄ‡i redoslijed i strukturu teksta. Ne postoji mehanizam za modeliranje odnosa izmeÄ‘u tema, poput hijerarhije ili vremenske dinamike, premda postoje proÅ¡irenja modela koja adresiraju ova ograniÄenja (Roberts i sur., 2014). KonaÄno, interpretabilnost tema nije garantirana jer model moÅ¾e producirati statistiÄki koherentne, ali semantiÄki nejasne teme.

U R-u, tematsko modeliranje provodi se pomoÄ‡u paketa topicmodels ili stm (Structural Topic Model), pri Äemu stm nudi dodatne moguÄ‡nosti poput ukljuÄivanja metapodataka u model.


## Analiza sentimenta

Analiza sentimenta, poznata i kao *opinion mining*, predstavlja skup metoda za automatsko odreÄ‘ivanje emocionalnog tona ili evaluativne orijentacije teksta. U najjednostavnijem obliku, cilj je klasificirati tekst kao pozitivan, negativan ili neutralan. Sofisticiranije varijante mogu mjeriti intenzitet sentimenta na kontinuiranoj skali, razlikovati viÅ¡e emocionalnih kategorija poput radosti, tuge, straha i ljutnje, ili identificirati aspekte objekta na koje se sentiment odnosi.

Za istraÅ¾ivanje masovne komunikacije analiza sentimenta pruÅ¾a alate za kvantifikaciju emocionalnog tona medijskog izvjeÅ¡tavanja i javnog diskursa. MoguÄ‡e je pratiti kako se sentiment prema odreÄ‘enom politiÄaru mijenja tijekom kampanje, usporeÄ‘ivati emocionalni ton izvjeÅ¡tavanja razliÄitih medija o istoj temi ili analizirati kako publika reagira na odreÄ‘ene dogaÄ‘aje.

RjeÄniÄki pristupi analizi sentimenta oslanjaju se na sentimentne leksikone, odnosno unaprijed definirane popise rijeÄi s pridruÅ¾enim sentiment vrijednostima. Ideja je jednostavna: tekst koji sadrÅ¾i mnogo pozitivnih rijeÄi vjerojatno izraÅ¾ava pozitivan sentiment, dok tekst bogat negativnim rijeÄima vjerojatno izraÅ¾ava negativan sentiment. IzraÄun sentimenta dokumenta najÄeÅ¡Ä‡e se provodi agregiranjem sentiment vrijednosti pojedinaÄnih rijeÄi.

@tbl-sentiment prikazuje usporedbu najÄeÅ¡Ä‡e koriÅ¡tenih sentimentnih leksikona.

| Leksikon | Broj rijeÄi | Tip kodiranja | Primjer |
|:---------|:------------|:--------------|:--------|
| AFINN | ~2.500 | NumeriÄka skala (-5 do +5) | "izvrstan" = +4, "grozan" = -4 |
| Bing | ~6.800 | Binarna klasifikacija | "sjajan" = pozitivno, "loÅ¡e" = negativno |
| NRC | ~14.000 | Emocije + polaritet | "smrt" = negativno, strah, tuga |

: Usporedba sentimentnih leksikona {#tbl-sentiment}

RjeÄniÄki pristupi imaju nekoliko znaÄajnih ograniÄenja. BuduÄ‡i da tretiraju svaku rijeÄ neovisno o kontekstu, ne mogu uhvatiti nijanse poput negacije, gdje fraza "nije loÅ¡e" zapravo izraÅ¾ava blago pozitivan sentiment premda sadrÅ¾i negativnu rijeÄ "loÅ¡e". TakoÄ‘er ne prepoznaju sarkazam i ironiju, gdje pozitivne rijeÄi mogu biti koriÅ¡tene za izraÅ¾avanje negativnog sentimenta.

Za hrvatski jezik dodatno ograniÄenje predstavlja oskudica validiranih sentimentnih leksikona. Dok za engleski postoje opseÅ¾ni resursi razvijani desetljeÄ‡ima, hrvatski leksikoni tipiÄno su manji i manje temeljito validirani. Projekti poput CroSentiLex (GlavaÅ¡, Karan i Å najder, 2012) razvijaju resurse za hrvatski, ali istraÅ¾ivaÄi moraju biti svjesni ograniÄene pokrivenosti i potencijalne potrebe za prilagodbom specifiÄnom korpusu.

Osim rjeÄniÄkih pristupa, postoje i pristupi temeljeni na strojnom uÄenju koji tretiraju analizu sentimenta kao klasifikacijski problem. U novije vrijeme, pristupi temeljeni na dubokom uÄenju i velikim jeziÄnim modelima postiÅ¾u impresivne rezultate. Modeli poput BERT-a, fino podeÅ¡eni za sentiment klasifikaciju, mogu razumjeti sloÅ¾ene obrasce i kontekstualne ovisnosti koje su bile izvan dosega ranijih metoda. Za hrvatski jezik dostupni su viÅ¡ejeziÄni modeli koji, premda nisu optimizirani specifiÄno za hrvatski, Äesto postiÅ¾u pristojne rezultate zahvaljujuÄ‡i prijenosu znanja iz bogatijih jezika.

U R-u, rjeÄniÄka analiza sentimenta provodi se primjenom sentimentnog rjeÄnika na matricu dokument-termin, dok se za pristupe temeljene na strojnom uÄenju koriste paketi koji pozivaju Python modele putem suÄelja reticulate.

KritiÄki osvrt na analizu sentimenta mora ukljuÄiti razmatranje valjanosti mjera. Agregirani rezultat koji kombinira sve rijeÄi u dokumentu moÅ¾e prikriti sloÅ¾enost evaluativne strukture teksta. ÄŒlanak koji uravnoteÅ¾eno prikazuje i pozitivne i negativne aspekte moÅ¾e imati neutralan agregirani sentiment, premda zapravo sadrÅ¾i snaÅ¾ne evaluacije u oba smjera.


## Ekstrakcija entiteta: koje aktere mediji spominju?

U analizi medijskog sadrÅ¾aja Äesto je relevantno ne samo Å¡to mediji govore, nego i o kome govore. Koji se politiÄki akteri najÄeÅ¡Ä‡e spominju? Koje organizacije dominiraju ekonomskim vijestima? Koje lokacije su u fokusu meÄ‘unarodnog izvjeÅ¡tavanja? Prepoznavanje imenovanih entiteta (*Named Entity Recognition*, NER) predstavlja tehniku koja automatski identificira i klasificira imena konkretnih objekata iz stvarnog svijeta.

Imenovani entiteti obuhvaÄ‡aju rijeÄi ili fraze koje se odnose na jedinstvene objekte koji imaju vlastita imena. TipiÄne kategorije ukljuÄuju osobe, organizacije, lokacije, vremenske oznake i novÄane vrijednosti. Proces prepoznavanja entiteta konceptualno se sastoji od dvije faze: detekcija identificira dijelove teksta koji predstavljaju entitete, a klasifikacija svakom detektiranom entitetu pridruÅ¾uje kategoriju.

Za oznaÄavanje entiteta koriste se standardizirane sheme poput BIO notacije (Begin-Inside-Outside). U ovoj notaciji svaki token dobiva oznaku koja kombinira poziciju u entitetu i kategoriju entiteta.

@tbl-ner prikazuje primjer ekstrakcije entiteta iz hipotetskog novinskog naslova.

| Tekst | Entitet | Kategorija |
|:------|:--------|:-----------|
| Premijer Novak | Novak | OSOBA |
| u Bruxellesu | Bruxelles | LOKACIJA |
| s Äelnicima EU | EU | ORGANIZACIJA |
| o 7 milijardi eura | 7 milijardi eura | NOVÄŒANA VRIJEDNOST |
| u petak | petak | VRIJEME |
| Europska komisija | Europska komisija | ORGANIZACIJA |

: Primjer ekstrakcije entiteta iz novinskog naslova {#tbl-ner}

Za istraÅ¾ivanje masovne komunikacije ekstrakcija entiteta otvara brojne analitiÄke moguÄ‡nosti. Analiza vidljivosti aktera moÅ¾e kvantificirati koliko Äesto se pojedini politiÄari, stranke ili institucije spominju u medijima i kako se ta vidljivost mijenja kroz vrijeme. MreÅ¾na analiza moÅ¾e rekonstruirati odnose izmeÄ‘u entiteta na temelju njihova supojavljivanja u tekstu.

Ekstrakcija entiteta suoÄava se s nekoliko izazova. ViÅ¡eznaÄnost je Äest problem jer ista rijeÄ moÅ¾e oznaÄavati entitete razliÄitih kategorija ovisno o kontekstu. Varijabilnost imenovanja odnosi se na Äinjenicu da se isti entitet moÅ¾e pojavljivati pod razliÄitim imenima. Za hrvatski jezik prepoznavanje entiteta dodatno je oteÅ¾ano morfoloÅ¡kim bogatstvom jer se imena pojavljuju u razliÄitim padeÅ¾ima.

Suvremeni sustavi za prepoznavanje entiteta temelje se na dubokom uÄenju i neuronskim mreÅ¾ama, posebno arhitekturama temeljenim na transformerima koji postiÅ¾u iznimne rezultate zahvaljujuÄ‡i sposobnosti hvatanja sloÅ¾enih kontekstualnih ovisnosti. Za hrvatski jezik, biblioteka classla (LjubeÅ¡iÄ‡ i Dobrovoljc, 2019) nudi specijalizirane modele za prepoznavanje entiteta.

@tbl-pristupi pruÅ¾a usporedni pregled vrsta analize teksta.

| Pristup | Prednosti | OgraniÄenja | TipiÄna primjena |
|:--------|:----------|:------------|:-----------------|
| Nadzirano uÄenje | Visoka preciznost za definirane kategorije | Zahtijeva oznaÄene podatke | Klasifikacija vijesti, detekcija laÅ¾nih vijesti |
| Nenadzirano uÄenje (LDA) | Otkriva nepoznate strukture | Zahtijeva interpretaciju | Eksploracija korpusa, praÄ‡enje tema |
| RjeÄniÄki pristupi | Transparentnost, bez potrebe za treniranjem | Kontekstualna neosjetljivost | Analiza sentimenta, longitudinalne studije |
| Ekstrakcija entiteta | Identificira konkretne aktere | ViÅ¡eznaÄnost, varijabilnost | Analiza vidljivosti, mreÅ¾na analiza |

: Usporedni pregled vrsta analize teksta {#tbl-pristupi}

ZakljuÄno, svaka od predstavljenih vrsta analize nudi jedinstvenu perspektivu na tekstualne podatke i odgovara na razliÄite vrste istraÅ¾ivaÄkih pitanja. Nadzirano uÄenje omoguÄ‡uje preciznu klasifikaciju prema unaprijed definiranim kategorijama. Nenadzirano uÄenje otkriva latentne tematske strukture i posebno je korisno u eksplorativnoj fazi istraÅ¾ivanja. RjeÄniÄki pristupi kvantificiraju sentiment i emocije na transparentan i reproducibilan naÄin. Ekstrakcija entiteta identificira kljuÄne aktere i omoguÄ‡uje analize vidljivosti i relacija. VjeÅ¡t istraÅ¾ivaÄ kombinira ove pristupe kako bi iz tekstualnih podataka izvukao bogat spektar uvida o medijskom diskursu i komunikacijskim praksama.


# Analiza na razini diskursa

U prethodnim poglavljima fokus je bio preteÅ¾no na analizi pojedinaÄnih rijeÄi ili dokumenata kao cjelina. MeÄ‘utim, znaÄenje u tekstu rijetko proizlazi iz izoliranih rijeÄi; ono nastaje kroz odnose izmeÄ‘u rijeÄi, kroz naÄine na koje se rijeÄi kombiniraju u veÄ‡e jedinice, kroz obrasce koji se ponavljaju kroz korpus i kroz implicitne strukture koje organiziraju diskurs. Kada novinar izvjeÅ¡tava o "ekonomskoj krizi", znaÄenje te fraze nije jednostavno zbroj znaÄenja rijeÄi "ekonomska" i "kriza", veÄ‡ cjelina s vlastitim konotacijama, asocijacijama i pragmatiÄkim implikacijama. SliÄno tome, naÄin na koji mediji uokviruju odreÄ‘enu temu, koje metafore koriste, koje aktere stavljaju u prvi plan, a koje marginaliziraju, ima dalekoseÅ¾ne posljedice za javno razumijevanje druÅ¡tvenih fenomena.

U ovom se poglavlju prelazi s razine pojedinaÄnih rijeÄi na razinu diskursa, odnosno na analizu Å¡irih jeziÄnih obrazaca i struktura koje organiziraju znaÄenje u tekstu. Poglavlje zapoÄinje n-gramima i kolokacijama, tehnikama koje omoguÄ‡uju identificiranje uobiÄajenih kombinacija rijeÄi i mjerenje snage njihove asocijacije. SrediÅ¡nji je dio posveÄ‡en analizi okvira, jednoj od najvaÅ¾nijih metoda u istraÅ¾ivanju masovne komunikacije. Razmatraju se i analiza retoriÄke strukture te mreÅ¾na analiza rijeÄi.


## N-grami i kolokacije

U prethodnim poglavljima pokazano je kako se medijske objave mogu analizirati kroz prizmu pojedinaÄnih rijeÄi, tretirajuÄ‡i dokument kao "vreÄ‡u rijeÄi" bez obzira na redoslijed i meÄ‘usobne odnose. MeÄ‘utim, jezik ne funkcionira kao nasumiÄni niz izoliranih rijeÄi. RijeÄi se kombiniraju u uobiÄajene obrasce, neke kombinacije su ÄeÅ¡Ä‡e nego Å¡to bi se oÄekivalo na temelju sluÄajnosti, a te kombinacije Äesto nose znaÄenje koje nadilazi znaÄenje sastavnih dijelova. Britanski lingvist John Rupert Firth saÅ¾eo je ovu ideju rijeÄima: "RijeÄ Ä‡eÅ¡ upoznati po druÅ¡tvu koje drÅ¾i" (Firth, 1957).

N-gram je uzastopni niz od n rijeÄi u tekstu. Kada je n jednak 1, govori se o unigramima, Å¡to odgovara analizi pojedinaÄnih rijeÄi. Kada je n jednak 2, govori se o bigramima ili parovima uzastopnih rijeÄi. Trigram je niz od tri uzastopne rijeÄi. Primjerice, reÄenica "Vlada je usvojila proraÄun" sadrÅ¾i sljedeÄ‡e bigrame: "Vlada je", "je usvojila", "usvojila proraÄun". Trigrami iste reÄenice bili bi: "Vlada je usvojila", "je usvojila proraÄun".

Analiza bigrama otkriva uzastopne parove rijeÄi koji se Äesto pojavljuju zajedno. U korpusu hrvatskih politiÄkih govora, najÄeÅ¡Ä‡i bigrami vjerojatno ukljuÄuju kombinacije poput "Republika Hrvatska", "Europska unija", "Hrvatski sabor", "socijalna pravda", "gospodarski rast" ili "fiskalna politika".

@tbl-bigrami prikazuje primjere najÄeÅ¡Ä‡ih bigrama iz hipotetskog korpusa hrvatskih politiÄkih govora.

| Bigram | Frekvencija | Tip fraze |
|:-------|:-----------:|:----------|
| Republika Hrvatska | 2.847 | SluÅ¾beni naziv |
| Europska unija | 1.923 | PolitiÄka organizacija |
| Hrvatski sabor | 1.456 | Institucija |
| gospodarski rast | 987 | Ekonomski termin |
| javni interes | 756 | Pravni pojam |
| socijalna pravda | 612 | IdeoloÅ¡ki koncept |

: Primjeri Äestih bigrama u korpusu politiÄkih govora {#tbl-bigrami}

Kolokacija je Å¡iri pojam od bigrama. Dok bigram zahtijeva da rijeÄi budu neposredno susjedne, kolokacija oznaÄava tendenciju dviju rijeÄi da se pojavljuju u meÄ‘usobnoj blizini, unutar odreÄ‘enog prozora konteksta, Äak i ako nisu neposredno susjedne. Kolokacije odraÅ¾avaju idiomatske i konvencionalne naÄine izraÅ¾avanja u jeziku.

Za identifikaciju statistiÄki znaÄajnih kolokacija koriste se mjere asocijacije koje kvantificiraju snagu veze izmeÄ‘u dviju rijeÄi. Uzajamna informacija (*Pointwise Mutual Information*, PMI) mjeri koliko je zajedniÄko pojavljivanje dviju rijeÄi ÄeÅ¡Ä‡e od oÄekivanog pod pretpostavkom nezavisnosti:

$$PMI(w_1, w_2) = \log_2 \frac{P(w_1, w_2)}{P(w_1) \cdot P(w_2)}$$

T-vrijednost (*t-score*) predstavlja alternativnu mjeru koja je konzervativnija i favorizira Äeste kolokacije:

$$t = \frac{O - E}{\sqrt{O}}$$

@tbl-mjere-kolok usporeÄ‘uje karakteristike razliÄitih mjera asocijacije.

| Mjera | Formula | Karakteristike | Primjena |
|:------|:--------|:---------------|:---------|
| PMI | $\log_2 \frac{P(w_1, w_2)}{P(w_1) \cdot P(w_2)}$ | Osjetljiva na rijetke rijeÄi | SpecifiÄni termini, idiomi |
| T-vrijednost | $\frac{O - E}{\sqrt{O}}$ | Favorizira Äeste kombinacije | UobiÄajeni jeziÄni obrasci |
| Log-likelihood | $2 \sum O \cdot \ln\frac{O}{E}$ | Robusna, statistiÄki testabilna | OpÄ‡a primjena |

: Usporedba mjera asocijacije za identifikaciju kolokacija {#tbl-mjere-kolok}

U kontekstu istraÅ¾ivanja masovne komunikacije, analiza n-grama i kolokacija moÅ¾e odgovoriti na niz pitanja. Koje su karakteristiÄne fraze pojedinih politiÄkih stranaka ili politiÄara? Kako se kolokacije odreÄ‘ene rijeÄi razlikuju izmeÄ‘u medija? Primjerice, koje rijeÄi mediji razliÄitih politiÄkih orijentacija povezuju s rijeÄju "migranti"? Jedan medij moÅ¾da preferira kolokacije poput "ilegalni migranti" i "migrantska kriza", dok drugi preferira "zaÅ¡tita izbjeglica" i "humanitarna pomoÄ‡". Ove razlike u kolokacijama odraÅ¾avaju razliÄite interpretativne okvire.

Longitudinalna analiza kolokacija moÅ¾e pratiti promjene u jeziÄnoj upotrebi kroz vrijeme. Kontekstualna analiza sentimenta predstavlja posebno vaÅ¾nu primjenu n-grama jer omoguÄ‡uje prepoznavanje obrazaca poput negacije ("nije loÅ¡") koji jednostavni rjeÄniÄki pristupi ne prepoznaju.

U R-u, analiza n-grama i kolokacija provodi se pomoÄ‡u paketa quanteda.textstats.


## Analiza okvira

Uokvirivanje (*framing*) predstavlja jedan od srediÅ¡njih koncepata u istraÅ¾ivanju masovne komunikacije. Ideja je da mediji ne samo prenose informacije o dogaÄ‘ajima, nego ih aktivno interpretiraju, odabiruÄ‡i odreÄ‘ene aspekte stvarnosti, naglaÅ¡avajuÄ‡i ih i ÄineÄ‡i ih istaknutijima, dok druge aspekte marginaliziraju ili potpuno ignoriraju. Robert Entman, jedan od najutjecajnijih teoretiÄara uokvirivanja, definirao je ovaj koncept na naÄin koji je postao kanonski u literaturi: uokvirivanje je proces odabira nekih aspekata percipirane stvarnosti i Äinjenja tih aspekata istaknutijima u komunikacijskom tekstu, na naÄin da se promovira odreÄ‘ena definicija problema, kauzalna interpretacija, moralna evaluacija i/ili preporuka tretmana (Entman, 1993).

Entmanova definicija identificira Äetiri kljuÄne funkcije okvira:

1. **Definicija problema** odreÄ‘uje o Äemu se zapravo radi, Å¡to je u igri, tko ili Å¡to je pogoÄ‘eno.
2. **Kauzalna interpretacija** identificira uzroke problema, pripisujuÄ‡i odgovornost odreÄ‘enim akterima, silama ili okolnostima.
3. **Moralna evaluacija** procjenjuje aktere i njihove postupke.
4. **Preporuka tretmana** sugerira rjeÅ¡enja, akcije koje bi trebalo poduzeti, politike koje bi trebalo implementirati.

KlasiÄan primjer koji ilustrira moÄ‡ uokvirivanja jest izvjeÅ¡tavanje o demonstracijama. Isti dogaÄ‘aj moÅ¾e biti uokviren kao "mirni prosvjed graÄ‘ana za svoja prava" ili kao "nasilni neredi koji ugroÅ¾avaju javni red". Odabir okvira utjeÄe na to kako Ä‡e publika razumjeti dogaÄ‘aj, koje uzroke Ä‡e pripisati, koje aktere Ä‡e smatrati odgovornima i koje reakcije Ä‡e smatrati prikladnima.

@tbl-okviri prikazuje Entmanove funkcije okvira s primjerima iz hrvatskog medijskog konteksta.

| Funkcija okvira | Definicija | Primjer: tema migracija |
|:----------------|:-----------|:------------------------|
| Definicija problema | Å to je u pitanju? | "Sigurnosna prijetnja" vs. "Humanitarna kriza" |
| Kauzalna interpretacija | Tko/Å¡to je uzrok? | "KrijumÄari" vs. "Ratovi i siromaÅ¡tvo" |
| Moralna evaluacija | Tko je dobar/loÅ¡? | "Ilegalni uljezi" vs. "Ranjive osobe" |
| Preporuka tretmana | Å to treba uÄiniti? | "Zatvoriti granice" vs. "PruÅ¾iti zaÅ¡titu" |

: Entmanove funkcije okvira primijenjene na temu migracija {#tbl-okviri}

RaÄunalna analiza okvira pokuÅ¡ava automatizirati ili barem podrÅ¾ati identifikaciju okvira u velikim korpusima teksta. LeksiÄki pristupi polaze od pretpostavke da se okviri manifestiraju kroz karakteristiÄne rijeÄi i fraze. IstraÅ¾ivaÄ moÅ¾e definirati "rjeÄnike okvira" koji sadrÅ¾e rijeÄi tipiÄne za pojedine okvire. Kolokacijska analiza pruÅ¾a sofisticiraniji pristup identifikaciji okvira.

Analiza metafora predstavlja posebno vaÅ¾an pristup jer metafore Äesto Äine srÅ¾ konceptualnih okvira. Kognitivni lingvisti George Lakoff i Mark Johnson (1980) pokazali su da metafore nisu samo stilsko ukraÅ¡avanje, veÄ‡ temeljni naÄin na koji konceptualiziramo apstraktne pojmove. Metafora "EKONOMIJA JE ZDRAVLJE" strukturira ekonomski diskurs kroz pojmove poput "zdravog gospodarstva", "bolesne ekonomije", "oporavka", "dijagnoze".

IstraÅ¾ivaÄ koji koristi raÄunalne metode za analizu okvira mora biti svjestan da one pruÅ¾aju indikatore, a ne definitivne identifikacije okvira. Najbolja praksa kombinira raÄunalno potpomognutu identifikaciju obrazaca s detaljnom analizom reprezentativnih primjera koji ilustriraju i validiraju te obrasce.


## Analiza retoriÄke strukture

Tekst nije samo skup reÄenica poredanih jedna za drugom; reÄenice su meÄ‘usobno povezane odnosima koji Äine tekst koherentnom cjelinom. Teorija retoriÄke strukture (*Rhetorical Structure Theory*, RST), koju su razvili William Mann i Sandra Thompson (1988), pruÅ¾a okvir za analizu tih odnosa. Prema RST-u, tekst se moÅ¾e rastaviti na elementarne diskurzivne jedinice, obiÄno klauzule, koje su povezane retoriÄkim relacijama poput uzroka, posljedice, kontrasta, elaboracije, dokaza i sliÄnih.

Razmotrimo primjer iz politiÄkog izvjeÅ¡tavanja: "Vlada je poveÄ‡ala porez na dohodak. To Ä‡e negativno utjecati na potroÅ¡nju graÄ‘ana." Dvije reÄenice povezane su relacijom uzrok-posljedica. Alternativna struktura mogla bi biti: "Vlada je poveÄ‡ala porez na dohodak, iako je obeÄ‡ala suprotno." Ovdje je relacija kontrast ili koncesija.

RST razlikuje nukleus i satelit u veÄ‡ini relacija. Nukleus je centralni, nezavisni dio koji moÅ¾e stajati sam, dok je satelit periferni dio koji dopunjuje, objaÅ¡njava ili modificira nukleus.

@tbl-rst prikazuje tipove diskurzivnih relacija i njihove leksiÄke signale.

| Tip relacije | TipiÄni veznici | Diskurzivna funkcija |
|:-------------|:----------------|:---------------------|
| Kauzalna | jer, zato, stoga, buduÄ‡i da | ObjaÅ¡njenje, argumentacija |
| Kontrastna | ali, meÄ‘utim, ipak, no | Suprotstavljanje, koncesija |
| Aditivna | i, takoÄ‘er, osim toga, nadalje | Nadogradnja, nabrajanje |
| Temporalna | zatim, potom, nakon toga, prije | Sekvenciranje, naracija |
| Kondicijska | ako, ukoliko, pod uvjetom | HipotetiÄki scenariji |

: Tipovi diskurzivnih relacija i njihovi leksiÄki signali {#tbl-rst}

Za istraÅ¾ivaÄe masovne komunikacije, Äak i djelomiÄna analiza retoriÄke strukture moÅ¾e biti vrijedna. Distribucija relacija u korpusu moÅ¾e otkriti karakteristike diskursa. Analiza diskurzivnih veznika predstavlja jednostavniji pristup koji ne zahtijeva potpunu RST analizu. Veznici poput "jer", "zato", "stoga" signaliziraju kauzalne relacije. Veznici poput "ali", "meÄ‘utim", "ipak" signaliziraju kontrastne relacije. Prebrojavanjem i analizom distribucije ovih veznika moÅ¾e se dobiti gruba slika retoriÄke organizacije teksta.


## MreÅ¾e rijeÄi i vizualizacija

Odnosi izmeÄ‘u rijeÄi u tekstu inherentno su mreÅ¾ni: rijeÄi su povezane s drugim rijeÄima kroz kolokacije, supojavljivanja i semantiÄke odnose. MreÅ¾na analiza rijeÄi eksplicira ovu strukturu, omoguÄ‡ujuÄ‡i vizualizaciju i kvantifikaciju kompleksnih obrazaca.

U mreÅ¾i rijeÄi, Ävorovi predstavljaju rijeÄi, a veze (bridovi) predstavljaju odnose izmeÄ‘u rijeÄi. Veze mogu biti definirane na razliÄite naÄine: bigram relacije, kolokacijske relacije, korelacijske relacije ili semantiÄke relacije.

MreÅ¾na analiza omoguÄ‡uje izraÄun raznih mreÅ¾nih mjera koje kvantificiraju strukturu diskursa:

- **Stupanj Ävora** (*degree*) mjeri broj veza koje Ävor ima, ukazujuÄ‡i na "povezanost" rijeÄi.
- **Bliskost Ävora** (*closeness centrality*) mjeri prosjeÄnu udaljenost Ävora od svih ostalih Ävorova.
- **MeÄ‘upoloÅ¾enost** (*betweenness centrality*) mjeri koliko Äesto Ävor leÅ¾i na najkraÄ‡im putevima izmeÄ‘u drugih Ävorova:

$$B(v) = \sum_{s \neq v \neq t} \frac{\sigma_{st}(v)}{\sigma_{st}}$$

- **Snaga Ävora** (*strength*) u vagiranim mreÅ¾ama mjeri ukupnu teÅ¾inu svih veza Ävora.

Detekcija zajednica (*community detection*) identificira skupine Ävorova koje su gusto povezane meÄ‘usobno, a slabo povezane s ostatkom mreÅ¾e. U mreÅ¾i rijeÄi, zajednice Äesto odgovaraju tematskim ili semantiÄkim skupinama.

@tbl-mrezne-metrike prikazuje mreÅ¾ne mjere i njihovu interpretaciju u analizi diskursa.

| Metrika | Definicija | Interpretacija u diskursu |
|:--------|:-----------|:--------------------------|
| Stupanj | Broj veza Ävora | Povezanost, prominentnost |
| MeÄ‘upoloÅ¾enost | Broj najkraÄ‡ih puteva kroz Ävor | Mostovna uloga, povezivanje tema |
| Bliskost | ProsjeÄna udaljenost do svih Ävorova | Globalna centralnost |
| Koeficijent klasteriranja | Udio povezanih susjeda | Lokalna kohezija |

: MreÅ¾ne metrike i njihova interpretacija u analizi diskursa {#tbl-mrezne-metrike}

U kontekstu istraÅ¾ivanja masovne komunikacije, mreÅ¾e rijeÄi mogu vizualizirati i kvantificirati strukturu diskursa na naÄine koji nadilaze jednostavne liste frekvencija. Usporedba mreÅ¾a izmeÄ‘u razliÄitih medija moÅ¾e otkriti sistematske razlike u naÄinu na koji organiziraju i povezuju koncepte. DinamiÄka analiza mreÅ¾a moÅ¾e pratiti kako se struktura diskursa mijenja kroz vrijeme.

MreÅ¾e supojavljivanja entiteta predstavljaju posebno korisnu primjenu. Ako se poveÅ¾u osobe koje se spominju u istim Älancima, dobiva se mreÅ¾a koja odraÅ¾ava medijsku percepciju odnosa izmeÄ‘u aktera.

Vizualizacija mreÅ¾e rijeÄi moÅ¾e biti moÄ‡an komunikacijski alat za prezentaciju nalaza istraÅ¾ivanja. PreporuÄuje se ograniÄiti mreÅ¾u na nekoliko stotina najvaÅ¾nijih Ävorova, koristiti veliÄinu Ävorova proporcionalnu njihovoj centralnosti, boju Ävorova za oznaÄavanje zajednica i debljinu veza proporcionalnu snazi asocijacije. U R-u, mreÅ¾na analiza i vizualizacija provode se pomoÄ‡u paketa igraph.

Integracija razliÄitih tehnika diskurzivne analize omoguÄ‡uje bogatiji uvid nego Å¡to bi svaka pojedinaÄno mogla pruÅ¾iti. TipiÄan integrirani radni tijek zapoÄinje eksplorativnom analizom kolokacija i mreÅ¾a rijeÄi, na temelju tih uvida razvijaju se specifiÄne hipoteze, a zatim se koristi ciljana analiza za kvantificiranje relevantnih obrazaca. KonaÄno, provodi se kvalitativna analiza reprezentativnih tekstova koji validiraju kvantitativne nalaze.


# OgraniÄenja metode

U prethodnim poglavljima predstavljen je Å¡irok raspon tehnika za raÄunalnu analizu teksta. ÄŒitatelj bi mogao steÄ‡i dojam da su ove metode gotovo neograniÄene u svojoj sposobnosti da iz velikih koliÄina nestrukturiranog teksta izvuku smislene uvide o druÅ¡tvenim fenomenima. MeÄ‘utim, svaka metoda ima svoja ograniÄenja, a kritiÄko razumijevanje tih ograniÄenja nuÅ¾no je za odgovorno i valjano istraÅ¾ivanje. Kao Å¡to su Grimmer, Roberts i Stewart (2022) upozorili, automatske metode analize teksta nisu zamjena za paÅ¾ljivo razmiÅ¡ljanje i pomno Äitanje te zahtijevaju opseÅ¾nu i problemski specifiÄnu validaciju.


## Valjanost i pouzdanost

Valjanost i pouzdanost tradicionalni su kriteriji kvalitete mjerenja u druÅ¡tvenim znanostima, a njihova primjena na raÄunalnu analizu teksta zahtijeva paÅ¾ljivu konceptualizaciju.

Valjanost mjerenja odnosi se na pitanje mjeri li mjera ono Å¡to se pretpostavlja da mjeri. U kontekstu analize teksta, valjanost ima nekoliko dimenzija. SadrÅ¾ajna valjanost pita pokriva li operacionalizacija sve relevantne aspekte koncepta. Konstruktna valjanost pita odgovara li mjera teorijskom konstruktu. Prediktivna valjanost pita predviÄ‘a li mjera druge varijable s kojima bi teorijski trebala biti povezana.

Problem valjanosti posebno je akutan kod prijenosa metoda i resursa iz jednog konteksta u drugi. Sentimentni rjeÄnik razvijen za analizu recenzija proizvoda na engleskom moÅ¾da neÄ‡e valjano mjeriti sentiment u hrvatskim politiÄkim komentarima.

Pouzdanost odnosi se na konzistentnost mjerenja. Za deterministiÄke algoritme poput prebrajanja rijeÄi iz rjeÄnika, pouzdanost je trivijalno zadovoljena jer isti ulazni podaci uvijek daju iste rezultate. MeÄ‘utim, mnogi suvremeni algoritmi ukljuÄuju stohastiÄke elemente poput nasumiÄne inicijalizacije parametara ili uzorkovanja tijekom treniranja, pa rezultati mogu varirati izmeÄ‘u pokretanja. IstraÅ¾ivaÄ mora provjeriti jesu li zakljuÄci robusni na ove varijacije, primjerice pokretanjem algoritma viÅ¡e puta s razliÄitim poÄetnim uvjetima.

Za procjenu pouzdanosti ljudskog kodiranja koje sluÅ¾i kao temelj za nadzirano uÄenje koriste se mjere poput Krippendorffovog alfa koeficijenta ili Cohenovog kappa koeficijenta, koji kvantificiraju stupanj slaganja izmeÄ‘u kodiraÄa uzimajuÄ‡i u obzir slaganje koje se moglo postiÄ‡i sluÄajno (Krippendorff, 2011).

@tbl-valjanost prikazuje dimenzije valjanosti i pouzdanosti u kontekstu raÄunalne analize teksta.

| Aspekt | Pitanje | Primjer u analizi teksta |
|:-------|:--------|:-------------------------|
| SadrÅ¾ajna valjanost | Pokriva li mjera sve aspekte koncepta? | Je li rjeÄnik sentimenta potpun za domenu? |
| Konstruktna valjanost | Odgovara li mjera teorijskom konstruktu? | Odgovaraju li LDA teme teorijskim konceptima? |
| Prediktivna valjanost | PredviÄ‘a li mjera povezane varijable? | Korelira li automatski sentiment s ljudskim procjenama? |
| Test-retest pouzdanost | Daje li metoda konzistentne rezultate? | Variraju li rezultati izmeÄ‘u pokretanja? |

: Dimenzije valjanosti i pouzdanosti u raÄunalnoj analizi teksta {#tbl-valjanost}


## Pristranost u podacima

Rezultati raÄunalne analize teksta mogu biti samo onoliko dobri koliko su dobri podaci na kojima se temelje. Pristranost (*bias*) moÅ¾e uÄ‡i u analizu na viÅ¡e toÄaka: u konstrukciji korpusa, u oznaÄenim podacima za treniranje i u samim algoritmima.

**Pristranost uzorkovanja** javlja se kada korpus nije reprezentativan za populaciju o kojoj se Å¾eli zakljuÄivati. Ako se analizira "hrvatsko novinarstvo", ali korpus sadrÅ¾i samo Älanke iz dvaju najveÄ‡ih portala, zakljuÄci se neÄ‡e moÄ‡i poopÄ‡iti na cjelokupno novinarstvo. Ako se analizira "javno mnijenje" na temelju objava na druÅ¡tvenim mreÅ¾ama, valja biti svjestan da korisnici druÅ¡tvenih mreÅ¾a nisu reprezentativni uzorak populacije.

**Temporalna pristranost** nastaje kada korpus pokriva samo odreÄ‘eno vremensko razdoblje. Jezik se mijenja, teme dolaze i odlaze, stilovi izvjeÅ¡tavanja evoluiraju. Model treniran na Älancima iz 2015. godine moÅ¾da neÄ‡e dobro funkcionirati na Älancima iz 2024. godine.

**Pristranost u oznaÄenim podacima** posebno je relevantna za nadzirano uÄenje. Ljudski koderi unose vlastite pristranosti i nekonzistentnosti. **AlgoritmiÄka pristranost** odnosi se na sistemske pogreÅ¡ke koje algoritmi uÄe iz podataka. JeziÄni modeli trenirani na velikim korpusima interneta uÄe i reproduciraju stereotipe i predrasude prisutne u tim podacima.

**Problem prekomjernog prilagoÄ‘avanja** (*overfitting*) zasluÅ¾uje posebnu paÅ¾nju. Javlja se kada model nauÄi specifiÄnosti trenaÅ¾nih podataka umjesto generalizirajuÄ‡ih obrazaca. Strategije za izbjegavanje ukljuÄuju podjelu podataka na trenaÅ¾ni, validacijski i testni skup, unakrsnu validaciju i regularizaciju.

**Domenski pomak** predstavlja poseban izazov koji nastaje kada se model primjenjuje na podatke koji dolaze iz drugaÄije distribucije nego trenaÅ¾ni podaci.


## Interpretabilnost i problem crne kutije

RazliÄiti algoritmi nude razliÄite stupnjeve interpretabilnosti, odnosno moguÄ‡nosti da istraÅ¾ivaÄ razumije zaÅ¡to je model donio odreÄ‘enu odluku.

Na jednom kraju spektra nalaze se rjeÄniÄki pristupi koji su potpuno transparentni. LogistiÄka regresija i sliÄni linearni modeli takoÄ‘er nude relativno dobru interpretabilnost jer svaka rijeÄ ima koeficijent koji pokazuje koliko i u kojem smjeru utjeÄe na predikciju.

Na drugom kraju spektra nalaze se duboki neuronski mreÅ¾ni modeli poput transformera koji su izrazito teÅ¡ki za interpretaciju. Ovi modeli imaju stotine milijuna ili Äak milijarde parametara organiziranih u kompleksne arhitekture. ZaÅ¡to je model odreÄ‘eni tekst klasificirao kao negativan? Odgovor se ne moÅ¾e jednostavno svesti na nekoliko kljuÄnih rijeÄi.

@tbl-interpretabilnost prikazuje stupnjeve interpretabilnosti razliÄitih metoda.

| Metoda | Interpretabilnost | Prednosti | Nedostaci |
|:-------|:------------------|:----------|:----------|
| RjeÄniÄki pristupi | Visoka | Potpuna transparentnost | OgraniÄena fleksibilnost |
| LogistiÄka regresija | Visoka | Koeficijenti pokazuju doprinos | Linearnost moÅ¾e biti ograniÄenje |
| Stabla odluÄivanja | Srednja | Vizualizacija pravila | Nestabilnost, prekomjerno prilagoÄ‘avanje |
| SVM | Niska do srednja | Dobra generalizacija | TeÅ¡ko interpretirati u visokim dimenzijama |
| Neuronske mreÅ¾e | Niska | Visoka prediktivna moÄ‡ | "Crna kutija" |
| Transformeri (BERT) | Vrlo niska | Vrhunske performanse | Gotovo potpuna neprozirnost |

: Stupnjevi interpretabilnosti razliÄitih metoda {#tbl-interpretabilnost}


## EtiÄka razmatranja

RaÄunalna analiza teksta, posebno kada se primjenjuje na ljudsku komunikaciju, otvara niz etiÄkih pitanja. Privatnost postaje sve relevantnija tema. Objave na druÅ¡tvenim mreÅ¾ama, komentari, poruke mogu sadrÅ¾avati osjetljive osobne informacije. ÄŒak i kada su ti tekstovi javno dostupni, to ne znaÄi da su njihovi autori pristali na to da budu predmet istraÅ¾ivanja.

Pristanak je sloÅ¾eno pitanje u kontekstu analize teksta. Tradicionalni model informiranog pristanka teÅ¡ko je primjenjiv kada se analiziraju tisuÄ‡e ili milijuni tekstova napisanih od razliÄitih autora.

Potencijalna zloupotreba istraÅ¾ivaÄkih rezultata zahtijeva anticipaciju moguÄ‡ih Å¡tetnih primjena. Transparentnost i reproducijalnost etiÄke su norme znanstvene prakse koje dobivaju posebnu teÅ¾inu u kontekstu raÄunalnih metoda. IstraÅ¾ivaÄ bi trebao jasno dokumentirati svoje metode, podatke i analitiÄke odluke na naÄin koji omoguÄ‡uje drugima da procijene i repliciraju rezultate.


## Validacija kao nuÅ¾nost

S obzirom na sva navedena ograniÄenja, validacija postaje nuÅ¾na komponenta svakog ozbiljnog istraÅ¾ivanja koje koristi raÄunalnu analizu teksta. Validacija nije jednokratni korak na kraju analize, veÄ‡ kontinuirani proces koji proÅ¾ima cijeli istraÅ¾ivaÄki tijek.

**Validacija reprezentacije** provjerava odgovara li naÄin na koji je tekst reprezentiran istraÅ¾ivaÄkom pitanju. **Validacija modela** provjerava proizvodi li model rezultate koji odgovaraju ljudskim procjenama. **Robusnost zakljuÄaka** testira jesu li zakljuÄci osjetljivi na analitiÄke odluke.

Grimmer, Roberts i Stewart (2022) zagovaraju pristup "ljudi u petlji" (*human-in-the-loop*) gdje raÄunalne metode sluÅ¾e kao alat za pojaÄavanje ljudskih analitiÄkih sposobnosti, a ne kao njihova zamjena. RaÄunalo moÅ¾e identificirati obrasce, sortirati dokumente, kvantificirati fenomene. Ali interpretacija znaÄenja, procjena relevantnosti, povezivanje s teorijom i donoÅ¡enje zakljuÄaka ostaju ljudske zadaÄ‡e.


# ZakljuÄak i buduÄ‡i pravci

PodruÄje raÄunalne analize teksta prolazi kroz razdoblje iznimno brzih promjena. Metode koje su prije samo nekoliko godina predstavljale vrhunac tehnologije danas su zamijenjene novim pristupima. Veliki jeziÄni modeli poput GPT-a, Clauda i Llame transformirali su naÄin na koji raÄunala procesiraju i generiraju tekst. Multimodalna analiza proÅ¡iruje fokus s Äistog teksta na integraciju slike, zvuka i videa. ViÅ¡ejeziÄni modeli smanjuju barijere za jezike s manjim resursima poput hrvatskog.


## Veliki jeziÄni modeli

Razvoj transformer arhitekture (Vaswani i sur., 2017) pokrenuo je revoluciju u obradi prirodnog jezika. Za istraÅ¾ivanje masovne komunikacije, veliki jeziÄni modeli otvaraju transformativne moguÄ‡nosti. Automatska anotacija tekstova postaje dostupnija jer se modeli mogu koristiti za klasifikaciju bez opseÅ¾nog ruÄnog oznaÄavanja. Zero-shot i few-shot uÄenje predstavljaju paradigmatski pomak jer omoguÄ‡uju klasifikaciju tekstova samo na temelju opisa kategorija, bez potrebe za stotinama oznaÄenih primjera.

MeÄ‘utim, s velikim moguÄ‡nostima dolaze i znaÄajni izazovi. Neprozirnost velikih modela nadilazi Äak i ranija ograniÄenja interpretabilnosti. Halucinacije, odnosno samopouzdano generiranje netoÄnih informacija, predstavljaju ozbiljan problem za primjene koje zahtijevaju faktiÄku toÄnost.


## Multimodalnost i viÅ¡ejeziÄnost

Suvremeni medijski sadrÅ¾aj rijetko je Äisto tekstualan. Vijesti na portalima redovito ukljuÄuju fotografije koje uokviruju priÄu. Objave na druÅ¡tvenim mreÅ¾ama kombiniraju tekst, slike, video i emoji. Modeli poput CLIP-a ili GPT-4V mogu procesirati istovremeno tekst i slike.

Za hrvatski jezik posebno je obeÄ‡avajuÄ‡i razvoj viÅ¡ejeziÄnih modela. Modeli poput mBERT-a ili XLM-RoBERTa trenirani su na tekstovima iz stotinu i viÅ¡e jezika istovremeno i mogu prenositi znanje nauÄeno na jezicima s obilnim resursima na jezike s manje resursa, ukljuÄujuÄ‡i hrvatski.

Razvoj sintetiÄkih podataka i generativne umjetne inteligencije donosi i nove izazove. Sposobnost velikih jeziÄnih modela da generiraju koherentan tekst ima dalekoseÅ¾ne implikacije, ukljuÄujuÄ‡i moguÄ‡nost proizvodnje dezinformacija na industrijskoj skali. Detekcija generiranog teksta postaje nova istraÅ¾ivaÄka domena.


## Pet principa odgovorne primjene

Na temelju literature i iskustva, moguÄ‡e je formulirati pet principa koji bi trebali voditi istraÅ¾ivaÄe masovne komunikacije u koriÅ¡tenju ovih metoda.

1. **Budite skromni u tvrdnjama.** Rezultati modela su aproksimacije, ne istine. ZakljuÄci trebaju odraÅ¾avati epistemiÄku skromnost primjerenu ograniÄenjima metoda.

2. **Budite transparentni u metodama.** Jasno dokumentirajte sve analitiÄke odluke, od pripreme podataka do interpretacije rezultata. OmoguÄ‡ite drugima da procijene i repliciraju rad.

3. **Budite skeptiÄni prema rezultatima.** Ne prihvaÄ‡ajte rezultate zdravo za gotovo samo zato Å¡to dolaze iz sofisticiranog algoritma. TraÅ¾ite alternativna objaÅ¡njenja, testirajte robusnost, validirajte s ljudskim procjenama.

4. **Budite etiÄni u primjeni.** Razmislite o moguÄ‡im Å¡tetama. PoÅ¡tujte privatnost subjekata Äiji tekstovi se analiziraju. Anticipirajte potencijalne zloupotrebe metoda i rezultata.

5. **Budite usmjereni na pitanja, ne na metode.** Metode su alati za odgovaranje na pitanja, ne ciljevi sami po sebi. Najbolja istraÅ¾ivanja poÄinju s vaÅ¾nim pitanjima o medijskoj komunikaciji i druÅ¡tvu, a zatim traÅ¾e najprikladnije metode za odgovaranje na ta pitanja.

@tbl-principi saÅ¾ima pet principa odgovorne primjene.

| Princip | Opis |
|:--------|:-----|
| Skromnost | Rezultati su aproksimacije, ne istine |
| Transparentnost | Dokumentirajte sve analitiÄke odluke |
| Skepticizam | Testirajte robusnost i alternativna objaÅ¡njenja |
| EtiÄnost | Razmislite o moguÄ‡im Å¡tetama i privatnosti |
| Usmjerenost na pitanja | Metode su alati, ne ciljevi |

: Pet principa odgovorne primjene raÄunalne analize teksta {#tbl-principi}


## ZavrÅ¡ne misli

RaÄunalna analiza teksta nije Äarobno rjeÅ¡enje koje automatizira istraÅ¾ivaÄki proces, veÄ‡ sofisticirani alat koji, kada se koristi promiÅ¡ljeno, moÅ¾e znaÄajno proÅ¡iriti doseg i dubinu komunikoloÅ¡kih istraÅ¾ivanja. UspjeÅ¡na primjena zahtijeva ne samo tehniÄke vjeÅ¡tine, veÄ‡ i teorijsku sofisticiranost, kritiÄku refleksiju i kontinuirani dijalog izmeÄ‘u kvantitativnih metoda i kvalitativnog razumijevanja.

S principima odgovorne primjene na umu, buduÄ‡nost raÄunalne analize teksta u istraÅ¾ivanju masovne komunikacije izgleda obeÄ‡avajuÄ‡e. Izazovi su znaÄajni, ali tako su i moguÄ‡nosti. IstraÅ¾ivaÄi koji se pripreme za ovu buduÄ‡nost bit Ä‡e u poziciji da pruÅ¾e uvide koji su i metodoloÅ¡ki rigorozni i supstantivno znaÄajni, doprinoseÄ‡i razumijevanju medijske komunikacije u sve sloÅ¾enijem informacijskom krajoliku.

ZavrÅ¡no, analiza teksta podsjeÄ‡a da tekst nije samo spremnik informacija koje treba izvuÄ‡i, veÄ‡ aktivni konstrukt koji oblikuje razumijevanje svijeta. Mediji ne samo izvjeÅ¡tavaju o stvarnosti; oni je interpretiraju, uokviruju i konstruiraju. Tehnike predstavljene u ovom poglavlju pruÅ¾aju alate za sistematsko istraÅ¾ivanje tih konstruktivnih procesa na razini koja nadilazi pojedinaÄne tekstove, omoguÄ‡ujuÄ‡i uvide u Å¡ire diskurzivne prakse koje oblikuju javnu sferu.


# Literatura {.unnumbered}

::: {#refs}
:::
